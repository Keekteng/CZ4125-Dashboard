{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import openai\n",
    "import json\n",
    "import ast\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set openai.api_key to the OPENAI environment variable\n",
    "openai.api_key = os.environ[\"api_key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to Note\n",
    "\n",
    "- Replace the key with your own key\n",
    "- Note that free api key is only limited to 3 calls per minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Education Background from Biography\n",
    "\n",
    "- system_msg and prompt to instruct LLM to return information in dictionary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_education_background(text):\n",
    "    system_msg = \"I am an AI assistant designed to help you extract educational background information from a given text. \\\n",
    "    I understand that the text contains a biography and I am capable of identifying and extracting details about the person's education, \\\n",
    "    including their Bachelor's, Master's, and PhD degrees. I also understand that after extracting the following educational information from the text\\\n",
    "    I have to dispaly it in the following format: {'Bachelor Degree': 'Institution', 'Master Degree': 'Institution', 'PhD': 'Institution'}. \\\n",
    "    If there is no information about a particular degree in the text, please return None for the corresponding key.\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on the biography below, tell me where did this person got his Bachelor's Degree, Master's Degree and PhD from. Return the results strictly in a dictionary format as such, {{\"Bachelor Degree\": \"Institution\", \"Master Degree\": \"Institution\", \"PhD\": \"Institution\"}}. If there is no information or if information is ambiguous about a particular degree in the text, please return \"None\" for the corresponding key. Also please make sure key and value is between double quote \"string\".\n",
    "\n",
    "    Biography:\n",
    "\n",
    "    {text}\n",
    "    \"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"system\", \"content\": system_msg },\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0)\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  \"Jie Zhang is a Professor of the School of Computer Science and Engineering at NTU Singapore, leading the Computational Intelligence Group. He obtained Ph.D. in Cheriton School of Computer Science from University of Waterloo and was the recipient of Alumni Gold Medal in 2009. Then he joined NTU as an Assistant Professor and was promoted to Associate Professor in 2015. From 2017-2018, he was appointed as Tan Chin Tuan Exchange Fellowship, New York University. He was also an Adjunct Fellow, Singapore Institute of Manufacturing Technology (SIMTech), A*STAR, from 2020-2021. His papers have been published by top journals and conferences and won several best paper awards. Jie Zhang is also active in serving research communities.\"\n",
    "\n",
    "response = extract_education_background(text=text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Bachelor Degree\": \"None\", \"Master Degree\": \"None\", \"PhD\": \"University of Waterloo\"}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = './prof_raw_data/'\n",
    "prefix = 'education'\n",
    "gpt_dir = './gpt_data/'\n",
    "\n",
    "dr_ntu_files = [os.path.join(raw_dir, f) for f in os.listdir(raw_dir) if os.path.isfile(os.path.join(raw_dir, f)) and 'dr_ntu' in f]\n",
    "\n",
    "for file in tqdm(dr_ntu_files[82:],position=0,leave=True):\n",
    "    with open(file,'r') as f:\n",
    "        prof_dict = json.load(f)\n",
    "    biography = prof_dict['biography']\n",
    "    name = prof_dict['full_name'].lower().replace(' ','_')\n",
    "    # pass in biography to gpt3.5\n",
    "    education_detail_str = extract_education_background(biography)\n",
    "    #convert string to dictionary\n",
    "    education_detail_dict = ast.literal_eval(education_detail_str.strip())\n",
    "    for key,value in education_detail_dict.items():\n",
    "        if value ==\"None\":\n",
    "            education_detail_dict[key] = None\n",
    "    with open(f\"{gpt_dir}{prefix}_{name}.json\",'w') as f:\n",
    "        json.dump(education_detail_dict,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Recent Research Interest\n",
    "\n",
    "- For each Professor, pass in last 3 years worth of paper to chatgpt and return a topic for each publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_research_interest(title,description,temp):\n",
    "    system_msg = \"I am an AI assistant designed to help you identify the field of research for a given publication based on its text description and title. \\\n",
    "    I understand that the text and title contains important information regarding the field of research for that publication and I will use those to help me identify a single research topic for that publication from a list of possible research topic.\\\n",
    "    I understand that the research topic that I return can only come from the following list; Artificial Intelligence,Machine Learning,Federated Learning,Reinforcement Learning,Multimodal learning,Natural Language Processing,Cybersecurity,Deep Learning,Quantum Computing,Computer Vision,Blockchain Technology,Internet of Things,Robotics,Human-Computer Interaction,Data-Mining\\\n",
    "    The research topic should be None if there is not enough information to determine which research topic it fall under in the list. \\\n",
    "    I understand that the response has to be between two tags, <answer> followed by </answer>, below is an example of what i should return. \\\n",
    "    <answer>Artificial Intelligence</answer>\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Based on the Title and Description of the publication provided, choose a research topic from the following list that best matches the publication. \n",
    "    Artificial Intelligence,Machine Learning,,Federated Learning,Reinforcement Learning,Natural Language Processing,Multimodal learning,Cybersecurity,Deep Learning,Quantum Computing,Computer Vision,Blockchain Technology,Internet of Things,Robotics,Human-Computer Interaction,Data-Mining\n",
    "    The research topic should be None if there is not enough information to determine which research topic it fall under in the list.\n",
    "    Your response has to be between two tags, <answer> followed by </answer>, below is an example of what you should return.\n",
    "    <answer>Artificial Intelligence</answer>. \n",
    "\n",
    "    Title: {title}\n",
    "    Description :{description}\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                        model=\"gpt-3.5-turbo\",\n",
    "                        messages=[{\"role\": \"system\", \"content\": system_msg },\n",
    "                                {\"role\": \"user\", \"content\": prompt}\n",
    "                        ],\n",
    "                        temperature=temp,\n",
    "                        request_timeout=15)\n",
    "                \n",
    "                return response['choices'][0]['message']['content']\n",
    "        except:\n",
    "             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = './prof_raw_data/'\n",
    "prefix = 'interest_'\n",
    "gpt_dir = './gpt_data/'\n",
    "\n",
    "goog_sch_files = [os.path.join(raw_dir, f) for f in os.listdir(raw_dir) if os.path.isfile(os.path.join(raw_dir, f)) and 'goog_sch' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [2:45:17<00:00, 137.74s/it]  \n"
     ]
    }
   ],
   "source": [
    "topic_list= ['Artificial Intelligence','Machine Learning','Natural Language Processing','Cybersecurity','Quantum Computing','Computer Vision','Blockchain Technology','Internet of Things','Robotics','Human-Computer Interaction','Data-Mining','None']\n",
    "for filepath in tqdm(goog_sch_files[14:],position=0,leave=True):\n",
    "    filename = filepath[25:-5]\n",
    "    with open(filepath,'r')as f:\n",
    "        profile = json.load(f)\n",
    "    \n",
    "    # Initialise dictionary of list to store recent field of research for each author\n",
    "    research_interests = {'interests':[]}\n",
    "\n",
    "    if 'articles' in profile:\n",
    "        articles = profile['articles']\n",
    "\n",
    "        # append recent_articles from last three years\n",
    "        cur_year = datetime.date.today().year\n",
    "        recent_articles = []\n",
    "        for article in articles:\n",
    "            if 'publication_date' in article:\n",
    "                if int(article['publication_date'].split('/')[0])>=(cur_year-2):\n",
    "                    recent_articles.append(article)\n",
    "\n",
    "        # For each recent_article, pass in title and description as inputs to gpt3.5\n",
    "        for recent_article in recent_articles:\n",
    "            temp =0 \n",
    "            # loop until gpt3.5 returns a output in the pre-defined format\n",
    "            while True:\n",
    "                # check if title and description exist for current article\n",
    "                if 'title' in recent_article and 'description' in recent_article:\n",
    "                    response = extract_research_interest(recent_article['title'],recent_article['description'],temp)\n",
    "                    # extract the answer between the tags <answer> </answer>\n",
    "                    research_topic = re.search(r\"(?<=<answer>).*?(?=</answer>)\",response)\n",
    "                    if research_topic:\n",
    "                        temp=0\n",
    "                        research_interests['interests'].append(research_topic[0])\n",
    "                        break\n",
    "                    # increase temperature if output is not in valid format\n",
    "                    else:\n",
    "                        temp+=0.1\n",
    "                        print(response)\n",
    "                else:\n",
    "                    #skip the current article if no title or description\n",
    "                    break        \n",
    "        \n",
    "    with open(f\"{gpt_dir}{prefix}{filename}.json\",'w') as f:\n",
    "        json.dump(research_interests,f)\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CZ4125",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
