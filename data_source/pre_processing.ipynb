{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import datetime\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Profile Page\n",
    "\n",
    "- Processing and raw_data for Individual Profile Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directories\n",
    "raw_dir = './prof_raw_data/'\n",
    "gpt_dir = './gpt_data/'\n",
    "processed_dir = './processed_data/'\n",
    "co_author_dir = './co_author_data/'\n",
    "profile_image_dir = './profile_image/'\n",
    "\n",
    "# prefixes\n",
    "goog_prefix = 'goog_sch_'\n",
    "dr_ntu_prefix = 'dr_ntu_'\n",
    "education_prefix = 'education_'\n",
    "interest_prefix = 'interest_'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scse_profile = pd.read_csv('./prof_raw_data/scse_profiles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publications per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pubs(articles):\n",
    "    cur_year = datetime.date.today().year\n",
    "    min_year  = np.inf\n",
    "    pub_yearly = {}\n",
    "    for article in articles:\n",
    "        if 'publication_date' in article:\n",
    "            pub_year = int(article['publication_date'].split('/')[0])\n",
    "            min_year = min(min_year,pub_year)\n",
    "            # unknown publish date\n",
    "            if pub_year>cur_year:\n",
    "                continue \n",
    "            else:               \n",
    "                pub_yearly[pub_year] = pub_yearly.get(pub_year,0) + 1\n",
    "    \n",
    "    # Filling in 0 for years without papers\n",
    "    for year in range(min_year,cur_year+1):\n",
    "        if year not in pub_yearly:\n",
    "            pub_yearly[year] = 0\n",
    "\n",
    "    return pub_yearly,min_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations Per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_citation(articles):\n",
    "    cur_year = datetime.date.today().year\n",
    "    min_year  = np.inf\n",
    "    citations_yearly = {}\n",
    "    for article in articles:\n",
    "        if 'citation_graph' in article and 'publication_date' in article:\n",
    "            pub_year = int(article['publication_date'].split('/')[0])\n",
    "            min_year = min(min_year,pub_year)\n",
    "\n",
    "            for year,citation_count in article['citation_graph'].items():\n",
    "                year = int(year)\n",
    "                if year<=cur_year:\n",
    "                    citations_yearly[year] = citations_yearly.get(year,0)+citation_count\n",
    "    \n",
    "\n",
    "    # Filling in 0 for years without citations\n",
    "    for year in range(min_year,cur_year+1):\n",
    "        if year not in citations_yearly:\n",
    "            citations_yearly[year] = 0\n",
    "    final_citations_yearly = {}\n",
    "    # Remove year < earliest publication_date, not possible to have citation before earliest publication date\n",
    "    for year,citation_count in citations_yearly.items():\n",
    "        if int(year)>=min_year:\n",
    "            final_citations_yearly[year] = citations_yearly[year]\n",
    "        \n",
    "\n",
    "    return final_citations_yearly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Citations per Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_citation(pubs_yearly,citation_yearly,pub_min_year):\n",
    "    avg_citation = {}\n",
    "    cur_year = datetime.date.today().year\n",
    "    citation_min_year = min(citation_yearly.keys())\n",
    "    if citation_min_year==pub_min_year:        \n",
    "        for year in range(pub_min_year,cur_year+1):\n",
    "            pub_count_to_date = 0\n",
    "            cite_count_to_date = 0\n",
    "            for temp_year in range(pub_min_year,year+1):\n",
    "                pub_count_to_date += pubs_yearly[temp_year]\n",
    "                cite_count_to_date += citation_yearly[temp_year]\n",
    "            avg_citation[year] = cite_count_to_date/pub_count_to_date\n",
    "    else:\n",
    "        for year in range(pub_min_year,citation_min_year):\n",
    "            avg_citation[year] = 0\n",
    "        for year in range(citation_min_year,cur_year+1):\n",
    "            pub_count_to_date = 0\n",
    "            cite_count_to_date = 0\n",
    "            for temp_year in  range(citation_min_year,year+1):\n",
    "                pub_count_to_date+= pubs_yearly[temp_year]\n",
    "                cite_count_to_date+=citation_yearly[temp_year]\n",
    "            avg_citation[year] = cite_count_to_date/pub_count_to_date\n",
    "\n",
    "    return avg_citation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Publication per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_pub(pubs_yearly,pub_min_year):\n",
    "    avg_pub = {}\n",
    "    cur_year = datetime.date.today().year\n",
    "    for year in range(pub_min_year,cur_year+1):\n",
    "        pub_count_to_date = 0\n",
    "        for temp_year in range(pub_min_year,year+1):\n",
    "            pub_count_to_date += pubs_yearly[temp_year]\n",
    "        avg_pub[year] = pub_count_to_date/(year+1-pub_min_year)\n",
    "\n",
    "    return avg_pub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h-Index\n",
    "\n",
    "- Calculate All-Time h-Index over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_h_index(articles):\n",
    "    h_index_yearly = {}\n",
    "\n",
    "    #current year\n",
    "    cur_year = datetime.date.today().year\n",
    "    # finding earliest publication date\n",
    "    min_year = np.inf\n",
    "    for article in articles:\n",
    "        if 'citation_graph' in article and 'publication_date' in article:\n",
    "            pub_year = int(article['publication_date'].split('/')[0])\n",
    "            min_year = min(min_year,pub_year)\n",
    "            if pub_year > cur_year:\n",
    "                continue\n",
    "            citation_count = 0\n",
    "            for year in range(pub_year,cur_year+1):\n",
    "                citation_count += article['citation_graph'].get(str(year),0)\n",
    "                h_index_yearly[year] = h_index_yearly.get(year,[]) + [citation_count]\n",
    "    for year in h_index_yearly:\n",
    "        h_index_value = sum(citation_counts>=idx+1 for idx, citation_counts in enumerate(sorted(h_index_yearly[year],reverse=True)))\n",
    "        h_index_yearly[year] = h_index_value\n",
    "\n",
    "    return h_index_yearly    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i10-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_i10_index(articles):\n",
    "    i10_index_yearly = {}\n",
    "\n",
    "    #current year\n",
    "    cur_year = datetime.date.today().year\n",
    "    # finding earliest publication date\n",
    "    min_year = np.inf\n",
    "    for article in articles:\n",
    "        if 'citation_graph' in article and 'publication_date' in article:\n",
    "            pub_year = int(article['publication_date'].split('/')[0])\n",
    "            min_year = min(min_year,pub_year)\n",
    "            if pub_year > cur_year:\n",
    "                continue\n",
    "            citation_count = 0\n",
    "            for year in range(pub_year,cur_year+1):\n",
    "                citation_count += article['citation_graph'].get(str(year),0)\n",
    "                i10_index_yearly[year] = i10_index_yearly.get(year,[]) + [citation_count]\n",
    "    for year in i10_index_yearly:\n",
    "        i10_index_value = sum(citation_counts>=10 for citation_counts in i10_index_yearly[year])\n",
    "        i10_index_yearly[year] = i10_index_value\n",
    "\n",
    "    return i10_index_yearly    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging all Data Sources\n",
    "\n",
    "- gpt_data, prof_raw_data and collaboration_network data\n",
    "- Save to processed_data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in scse_profile['name']:\n",
    "    filename = name.lower().replace(' ','_')\n",
    "    # read from raw data source and gpt data source\n",
    "    with open(f\"{raw_dir}{goog_prefix}{filename}.json\",'r') as f:\n",
    "        goog_sch_profile = json.load(f)\n",
    "\n",
    "    with open(f\"{raw_dir}{dr_ntu_prefix}{filename}.json\",'r')as f:\n",
    "        dr_ntu_profile = json.load(f)\n",
    "\n",
    "    with open(f\"{gpt_dir}{education_prefix}{filename}.json\",'r') as f:\n",
    "        education_info = json.load(f)\n",
    "    \n",
    "    with open(f\"{gpt_dir}{interest_prefix}{filename}.json\",'r') as f:\n",
    "        research_interest = json.load(f)\n",
    "\n",
    "    with open(f\"{co_author_dir}{filename}.json\",'r') as f:\n",
    "        co_author_network = json.load(f)\n",
    "    \n",
    "    # keys to add directly to merged profile\n",
    "    goog_sch_keys = ['goog_sch_url','citation_table','citation_graph','co_authors_url']\n",
    "    dr_ntu_keys = ['full_name','image_path','email','name_card','designations','urls','biography','grants','patents','keywords']\n",
    "    \n",
    "    merged_profile = {}\n",
    "\n",
    "    for key in dr_ntu_keys:\n",
    "        merged_profile[key] = dr_ntu_profile[key]\n",
    "        \n",
    "    if goog_sch_profile:\n",
    "        for key in goog_sch_keys:\n",
    "            merged_profile[key] = goog_sch_profile[key]\n",
    "    else:\n",
    "        for key in goog_sch_keys:\n",
    "            if key=='goog_sch_url':\n",
    "                merged_profile[key] = None\n",
    "            elif key=='interests':\n",
    "                merged_profile[key] = []\n",
    "            elif key=='citation_table':\n",
    "                merged_profile[key] = {}\n",
    "            elif key=='citation_graph':\n",
    "                merged_profile[key] = {}\n",
    "            elif key=='co_authors_url':\n",
    "                merged_profile[key] = []\n",
    "    if 'google_scholar' not in merged_profile['urls']:\n",
    "        merged_profile['urls']['google_scholar'] = merged_profile['goog_sch_url']\n",
    "    merged_profile.pop('goog_sch_url')\n",
    "    if 'scopus' not in merged_profile['urls']:\n",
    "        merged_profile['urls']['scopus'] = None\n",
    "    if 'web_of_science' not in merged_profile['urls']:\n",
    "        merged_profile['urls']['web_of_science'] = None\n",
    "\n",
    "    # add education background information generated from chatgpt\n",
    "    merged_profile['education'] = education_info\n",
    "\n",
    "    # add recent research interest generated based on author's recent articles\n",
    "    research_interest = list(set(research_interest['interests']))\n",
    "    # remove None which is returned if gpt3.5 is unsure of field of research for a specific article and invalid outputs that are very long(sentences)\n",
    "    research_interest = [interest for interest in research_interest if interest!=\"None\" and len(interest)<50]\n",
    "    merged_profile['interests'] = research_interest\n",
    "\n",
    "    # add co_author_network dictionary\n",
    "    merged_profile['co_author_network'] = co_author_network\n",
    "\n",
    "    pub_yearly = {}\n",
    "    citation_yearly = {}\n",
    "    h_index_yearly = {}\n",
    "    avg_citation_yearly = {}\n",
    "    if 'articles' in goog_sch_profile:\n",
    "        # adding pre-processed information\n",
    "        pub_yearly,min_year = calc_pubs(goog_sch_profile['articles'])\n",
    "        citation_yearly = calc_citation(goog_sch_profile['articles'])\n",
    "        h_index_yearly = calc_h_index(goog_sch_profile['articles'])\n",
    "        i10_index_yearly = calc_i10_index(goog_sch_profile['articles'])\n",
    "        avg_citation_yearly = calc_avg_citation(pub_yearly,citation_yearly,min_year)\n",
    "        avg_pub_yearly = calc_avg_pub(pub_yearly,min_year)\n",
    "\n",
    "        merged_profile['pub_graph'] = pub_yearly\n",
    "        merged_profile['citation_graph'] = citation_yearly\n",
    "        merged_profile['h_index_graph'] = h_index_yearly\n",
    "        merged_profile['i10_index_graph'] = i10_index_yearly\n",
    "        merged_profile['avg_citation_graph'] = avg_citation_yearly\n",
    "        merged_profile['avg_pub_graph'] = avg_pub_yearly\n",
    "    else:\n",
    "        merged_profile['pub_graph'] = {}\n",
    "        merged_profile['citation_graph'] = {}\n",
    "        merged_profile['h_index_graph'] = {}\n",
    "        merged_profile['i10_index_graph'] = {}\n",
    "        merged_profile['avg_citation_graph'] = {}\n",
    "        merged_profile['avg_pub_graph'] = {}\n",
    "        \n",
    "    with open(f\"{processed_dir}{filename}.json\",'w') as f:\n",
    "        json.dump(merged_profile,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCSE Page\n",
    "\n",
    "- Processing the research interest labels returned by gpt\n",
    "    - Merge duplicate label e.g Adversarial Attack vs Adversarial Attack\n",
    "- Add recent research interest, since 2018 citation count, publication count, h-index,i10-index to scse profile table to be displayed\n",
    "- Merge to ./prof_raw_data/scse_profile.csv and save in ./processed_data/scse_profile.csv to be displayed on streamlit dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scse_profile = pd.read_csv('./prof_raw_data/scse_profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scse_profile = scse_profile.drop(columns=['Unnamed: 0','dr_ntu_url'])\n",
    "new_cols = ['name','email']\n",
    "scse_profile = scse_profile[new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = scse_profile['name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all labels to set and merge manually \n",
    "unique_research_interest = set()\n",
    "for name in name_list:\n",
    "    with open(f\"./gpt_data/interest_{name.lower().replace(' ','_')}.json\",'r')as f:\n",
    "        profile_interest = json.load(f)\n",
    "\n",
    "    if profile_interest['interests']:\n",
    "        # add recent research interest generated based on author's recent articles\n",
    "        profile_interest = list(set(profile_interest['interests']))\n",
    "        # remove None which is returned if gpt3.5 is unsure of field of research for a specific article and invalid outputs that are very long(sentences)\n",
    "        profile_interest = [interest for interest in profile_interest if interest!=\"None\" and len(interest)<50]\n",
    "        for interest in profile_interest:\n",
    "            unique_research_interest.add(interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels to Merge\n",
    "- All variations of \n",
    "    - Adversarial Attack\n",
    "    - Autonomous Driving System\n",
    "    - Brain Computer Interface\n",
    "    - Explainable AI\n",
    "    - Generative Adversarial Networks\n",
    "    - Graph Convolution Networks\n",
    "    - Medical Image Segmentation\n",
    "    - Wireless Communication Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adversarial Attack',\n",
       " 'Adversarial Attacks',\n",
       " 'Adversarial Examples',\n",
       " 'Artificial Intelligence',\n",
       " 'Autonomous Driving System Testing',\n",
       " 'Autonomous Driving Systems',\n",
       " 'Autonomous Driving Systems (ADSs)',\n",
       " 'Autonomous Vehicles',\n",
       " 'Biomedical Engineering',\n",
       " 'Blockchain Technology',\n",
       " 'Brain Machine Interface',\n",
       " 'Brain-Computer Interface',\n",
       " 'Brain-Computer Interface (BCI)',\n",
       " 'Cloud Computing',\n",
       " 'Cloud Gaming',\n",
       " 'Collaborative Filtering',\n",
       " 'Computer Vision',\n",
       " 'Cryptanalysis',\n",
       " 'Cybersecurity',\n",
       " 'Data-Mining',\n",
       " 'Database Systems',\n",
       " 'Deep Learning',\n",
       " 'Distributed Computing',\n",
       " 'Domain Confused Contrastive Learning',\n",
       " 'Energy Harvesting',\n",
       " 'Evolutionary Computation',\n",
       " 'Explainable AI',\n",
       " 'Explainable AI (XAI)',\n",
       " 'Explainable AI Design',\n",
       " 'Explainable Artificial Intelligence',\n",
       " 'Explainable Artificial Intelligence (XAI)',\n",
       " 'Fairness as Decision Rationale Alignment',\n",
       " 'Fairness in Artificial Intelligence',\n",
       " 'Federated Learning',\n",
       " 'Game Theory',\n",
       " 'Generative Adversarial Networks',\n",
       " 'Generative Adversarial Networks (GANs)',\n",
       " 'Graph Convolution Networks',\n",
       " 'Graph Convolutional Network (GCN)',\n",
       " 'Graph Convolutional Networks',\n",
       " 'Graph Neural Networks',\n",
       " 'Graph Percolation Embeddings',\n",
       " 'Graph Representation Learning',\n",
       " 'Human-Computer Interaction',\n",
       " 'Internet of Things',\n",
       " 'Interpreting Deep Neural Networks',\n",
       " 'Knowledge Graph Completion',\n",
       " 'Machine Learning',\n",
       " 'Medical Image Segmentation',\n",
       " 'Medical Imaging',\n",
       " 'Multimodal learning',\n",
       " 'Natural Language Processing',\n",
       " 'Neuromorphic Computing',\n",
       " 'Neuroscience',\n",
       " 'Operations Research',\n",
       " 'Privacy-Enhanced Neural Network',\n",
       " 'Probabilistic Programming',\n",
       " 'Quantum Computing',\n",
       " 'Recommender Systems',\n",
       " 'Rehabilitation Exercise',\n",
       " 'Reinforcement Learning',\n",
       " 'Robotics',\n",
       " 'Social Networks',\n",
       " 'Software Engineering',\n",
       " 'Software Testing',\n",
       " 'Speaker Verification',\n",
       " 'Speech Separation',\n",
       " 'Virtual Reality',\n",
       " 'Visible Light Communication',\n",
       " 'Wireless Communication',\n",
       " 'Wireless Communication Systems',\n",
       " 'Wireless Communications',\n",
       " 'Wireless Networks',\n",
       " 'Wireless Sensing',\n",
       " 'Zero-Shot Learning'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_research_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_interests(interest):\n",
    "    if 'Adversarial' in interest:\n",
    "        return \"Adversarial Attack\"\n",
    "    if \"Autonomous Driving\" in  interest or \"Autonomous Vehicle\" in interest:\n",
    "        return \"Autonomous Driving System\"\n",
    "    if \"Brain-Computer Interface\" in interest:\n",
    "        return \"Brain-Computer Interface\"\n",
    "    if \"Explainable AI\" in interest or \"Explainable Artificial Intelligence\" in interest:\n",
    "        return \"Explainable AI\"\n",
    "    if 'Graph Convolutional Network' in interest:\n",
    "        return 'Graph Convolutional Network'\n",
    "    if 'Wireless Communication' in interest:\n",
    "        return \"Wireless Communication\"\n",
    "    return interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faculty Member Table \n",
    "- save it as faculty_member.csv in processed_data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging professor's recent research interest that we got from chatgpt\n",
    "interest_list = []\n",
    "pub_list = []\n",
    "citation_list = []\n",
    "for name in name_list:\n",
    "    with open(f\"./gpt_data/interest_{name.lower().replace(' ','_')}.json\",'r')as f:\n",
    "        profile_interest = json.load(f)\n",
    "\n",
    "    with open(f\"./prof_raw_data/goog_sch_{name.lower().replace(' ','_')}.json\",'r') as f:\n",
    "        goog_sch_profile = json.load(f)\n",
    "\n",
    "    if profile_interest['interests']:\n",
    "        # add recent research interest generated based on author's recent articles\n",
    "        profile_interest = list(set(profile_interest['interests']))\n",
    "        # remove None which is returned if gpt3.5 is unsure of field of research for a specific article and invalid outputs that are very long(sentences)\n",
    "        filtered_interest = []\n",
    "        for interest in profile_interest:\n",
    "            if interest!=\"None\" and len(interest)<50:\n",
    "                filtered_interest.append(merging_interests(interest))\n",
    "        interest_list.append(','.join(filtered_interest))\n",
    "    else:\n",
    "        interest_list.append(' ')\n",
    "\n",
    "    if 'articles' in goog_sch_profile:\n",
    "        if goog_sch_profile['articles']:\n",
    "            recent_pub_count = 0 \n",
    "            recent_citation_count = 0\n",
    "            for article in goog_sch_profile['articles']:\n",
    "                if 'publication_date' in article:\n",
    "                    if int(article['publication_date'].split('/')[0])>=2020:\n",
    "                        recent_pub_count+=1\n",
    "                        if 'total_citations' in article:\n",
    "                            recent_citation_count+=article['total_citations']\n",
    "            citation_list.append(recent_citation_count)\n",
    "            pub_list.append(recent_pub_count)           \n",
    "    else:\n",
    "        citation_list.append(np.nan)\n",
    "        pub_list.append(np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scse_profile['Recent Research Interest'] = interest_list\n",
    "scse_profile['Recent Publication Count'] = pub_list\n",
    "scse_profile['Recent Citation Count'] = citation_list\n",
    "scse_profile['Avg Citation Per Paper'] = (scse_profile['Recent Citation Count']/scse_profile['Recent Publication Count']).round(2)\n",
    "\n",
    "scse_profile = scse_profile.rename(columns={'name':'Name','email':'Email'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scse_profile.to_csv('./processed_data/faculty_member.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Recent Research Interest</th>\n",
       "      <th>Recent Publication Count</th>\n",
       "      <th>Recent Citation Count</th>\n",
       "      <th>Avg Citation Per Paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A S Madhukumar</td>\n",
       "      <td>asmadhukumar@ntu.edu.sg</td>\n",
       "      <td>Cybersecurity,Reinforcement Learning,Deep Lear...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>7.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alexei Sourin</td>\n",
       "      <td>assourin@ntu.edu.sg</td>\n",
       "      <td>Machine Learning,Multimodal learning,Deep Lear...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>6.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anupam Chattopadhyay</td>\n",
       "      <td>anupam@ntu.edu.sg</td>\n",
       "      <td>Cybersecurity,Neuromorphic Computing,Natural L...</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>9.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anwitaman Datta</td>\n",
       "      <td>anwitaman@ntu.edu.sg</td>\n",
       "      <td>Cybersecurity,Natural Language Processing,Bloc...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arvind Easwaran</td>\n",
       "      <td>arvinde@ntu.edu.sg</td>\n",
       "      <td>Cybersecurity,Reinforcement Learning,Machine L...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Zhang Jie</td>\n",
       "      <td>zhangj@ntu.edu.sg</td>\n",
       "      <td>Operations Research,Recommender Systems,Reinfo...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>21.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Zhang Tianwei</td>\n",
       "      <td>tianwei.zhang@ntu.edu.sg</td>\n",
       "      <td>Cybersecurity,Artificial Intelligence,Reinforc...</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>10.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Zhao Jun</td>\n",
       "      <td>junzhao@ntu.edu.sg</td>\n",
       "      <td>Adversarial Attack,Wireless Communication,Cybe...</td>\n",
       "      <td>172.0</td>\n",
       "      <td>5110.0</td>\n",
       "      <td>29.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Zheng Jianmin</td>\n",
       "      <td>asjmzheng@ntu.edu.sg</td>\n",
       "      <td>Machine Learning,Multimodal learning,Computer ...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Zinovi Rabinovich</td>\n",
       "      <td>zinovi@ntu.edu.sg</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name                     Email  \\\n",
       "0         A S Madhukumar   asmadhukumar@ntu.edu.sg   \n",
       "1          Alexei Sourin       assourin@ntu.edu.sg   \n",
       "2   Anupam Chattopadhyay         anupam@ntu.edu.sg   \n",
       "3        Anwitaman Datta      anwitaman@ntu.edu.sg   \n",
       "4        Arvind Easwaran        arvinde@ntu.edu.sg   \n",
       "..                   ...                       ...   \n",
       "81             Zhang Jie         zhangj@ntu.edu.sg   \n",
       "82         Zhang Tianwei  tianwei.zhang@ntu.edu.sg   \n",
       "83              Zhao Jun        junzhao@ntu.edu.sg   \n",
       "84         Zheng Jianmin      asjmzheng@ntu.edu.sg   \n",
       "85     Zinovi Rabinovich         zinovi@ntu.edu.sg   \n",
       "\n",
       "                             Recent Research Interest  \\\n",
       "0   Cybersecurity,Reinforcement Learning,Deep Lear...   \n",
       "1   Machine Learning,Multimodal learning,Deep Lear...   \n",
       "2   Cybersecurity,Neuromorphic Computing,Natural L...   \n",
       "3   Cybersecurity,Natural Language Processing,Bloc...   \n",
       "4   Cybersecurity,Reinforcement Learning,Machine L...   \n",
       "..                                                ...   \n",
       "81  Operations Research,Recommender Systems,Reinfo...   \n",
       "82  Cybersecurity,Artificial Intelligence,Reinforc...   \n",
       "83  Adversarial Attack,Wireless Communication,Cybe...   \n",
       "84  Machine Learning,Multimodal learning,Computer ...   \n",
       "85                                                      \n",
       "\n",
       "    Recent Publication Count  Recent Citation Count  Avg Citation Per Paper  \n",
       "0                       32.0                  255.0                    7.97  \n",
       "1                       22.0                  140.0                    6.36  \n",
       "2                      107.0                 1011.0                    9.45  \n",
       "3                       24.0                   81.0                    3.38  \n",
       "4                       47.0                  204.0                    4.34  \n",
       "..                       ...                    ...                     ...  \n",
       "81                      65.0                 1400.0                   21.54  \n",
       "82                     156.0                 1612.0                   10.33  \n",
       "83                     172.0                 5110.0                   29.71  \n",
       "84                      46.0                  349.0                    7.59  \n",
       "85                       NaN                    NaN                     NaN  \n",
       "\n",
       "[86 rows x 6 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scse_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faculty Metrics\n",
    "\n",
    "- Total Number of Publications, Citations,Grants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = {'pubs':{'Total Publications':0,'delta':0},'citations':{'Total Citations':0,'delta':0},'total_grants':0,'total_patents':0}\n",
    "for name in name_list:\n",
    "    with open(f\"{raw_dir}{dr_ntu_prefix}{name.lower().replace(' ','_')}.json\",'r')as f:\n",
    "        dr_ntu_profile = json.load(f)\n",
    "\n",
    "    with open(f\"{processed_dir}{name.lower().replace(' ','_')}.json\", 'r')as f:\n",
    "        processed_profile = json.load(f)\n",
    "    cur_year = str(datetime.date.today().year)\n",
    "    if cur_year in processed_profile['pub_graph']:\n",
    "        metric['pubs']['delta'] += processed_profile['pub_graph'][cur_year]\n",
    "    if cur_year in processed_profile['citation_graph']:\n",
    "        metric['citations']['delta'] += processed_profile['citation_graph'][cur_year]\n",
    "    metric['pubs']['Total Publications'] += sum(processed_profile['pub_graph'].values())\n",
    "    metric['citations']['Total Citations'] += sum(processed_profile['citation_graph'].values())\n",
    "    metric['total_grants'] += len(processed_profile['grants'])\n",
    "    metric['total_patents'] += len(processed_profile['patents'])\n",
    "    \n",
    "with open('./processed_data/scse_metric.json','w')as f:\n",
    "    json.dump(metric,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CZ4125",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
