{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Sources of Data\n",
    "\n",
    "1. Google Scholar \n",
    "    - Description, Year, Venues of all Publications by invidivual (Google Scholar)\n",
    "    - all citation related details (Google Scholar)\n",
    "    - co authors detail & research interest (Google Scholar) \n",
    "2. DR-NTU\n",
    "    - biography, websites ,grants,email,name, designations (DR-NTU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import requests\n",
    "from thefuzz import fuzz\n",
    "import re\n",
    "import itertools\n",
    "from selenium import webdriver\n",
    "from selenium_stealth import stealth\n",
    "from selenium.webdriver.common.by import By\n",
    "import os,json\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Google Scholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n    {\\n        \\'name\\': \"Li Boyang\",\\n        \\'interest\\': [\\'ML\\',\\'AI\\'],\\n        \\'articles\\':[\\n            {\\n                \\'Title\\': \"Story Generation\",\\n                \\'CO-Authors\\' : [\\'Mark Riedl\\',\\'LOL\\'],\\n                \\'date\\': str,\\n                \\'venue\\': str,\\n                \\'Description: str,\\n                \\'Cited by\\': int,\\n                \\'citation_graph\\':dict\\n            },\\n        ],\\n        \\'co_authors_profile_url\\': [\\n            \\'https://scholar.google.com/citations?user=Yg_QjxcAAAAJ&hl=en\\',\\n        ]\\n        \\'all_citation_count\\': int\\n        \\'recent_citation_count: int\\n        }\\n\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "    {\n",
    "        'name': \"Li Boyang\",\n",
    "        'interest': ['ML','AI'],\n",
    "        'articles':[\n",
    "            {\n",
    "                'Title': \"Story Generation\",\n",
    "                'CO-Authors' : ['Mark Riedl','LOL'],\n",
    "                'date': str,\n",
    "                'venue': str,\n",
    "                'Description: str,\n",
    "                'Cited by': int,\n",
    "                'citation_graph':dict\n",
    "            },\n",
    "        ],\n",
    "        'co_authors_profile_url': [\n",
    "            'https://scholar.google.com/citations?user=Yg_QjxcAAAAJ&hl=en',\n",
    "        ]\n",
    "        'all_citation_count': int\n",
    "        'recent_citation_count: int\n",
    "        }\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium stealth driver used for scraping Google Scholar\n",
    "def create_driver(debug=False):\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    if debug==False:\n",
    "        options.add_argument(\"--headless\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    driver = webdriver.Chrome(\n",
    "        options=options\n",
    "    )\n",
    "    stealth(driver,\n",
    "            # user_agent=agent,\n",
    "            languages=[\"en-US\", \"en\"],\n",
    "            vendor=\"Google Inc.\",\n",
    "            platform=\"Win32\",\n",
    "            webgl_vendor=\"Intel Inc.\",\n",
    "            renderer=\"Intel Iris OpenGL Engine\",\n",
    "            fix_hairline=True,\n",
    "            )\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Google Scholar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scholarly Name Search\n",
    "- Through Name search by appending Nanyang Technological University at the back of the name\n",
    "- Does not cover all cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prof_details(details, filename, dir='./prof_raw_data'):\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    filename = dir + '/' + filename\n",
    "        \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(details, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name_combinations(name):\n",
    "    words = name.split()\n",
    "    combinations = []\n",
    "    for r in range(2, len(words) + 1):\n",
    "        combinations.extend(list(itertools.combinations(words, r)))\n",
    "    combinations = [' '.join(combination).strip(',') for combination in combinations]\n",
    "    return combinations[::-1]\n",
    "\n",
    "\n",
    "def extract_goog_sch_profile(author_full_name):\n",
    "\n",
    "    BASE_URL = 'https://scholar.google.com'\n",
    "    if len(author_full_name.split())>2:\n",
    "        name_perm_list = generate_name_combinations(author_full_name)\n",
    "    else:\n",
    "        name_perm_list = [author_full_name]\n",
    "\n",
    "    prof_result = {}\n",
    "    for name in name_perm_list:\n",
    "        query_param = name+\" Nanyang Technological University\"\n",
    "        search_url = f\"https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors={query_param}&btnG=\"\n",
    "\n",
    "        driver = create_driver()\n",
    "        driver.get(search_url)\n",
    "        time.sleep(3)  # wait for the page to load\n",
    "\n",
    "        # find professors' descriptions and emails\n",
    "        dsc_elements = driver.find_elements(By.CLASS_NAME, 'gs_ai_aff') \n",
    "        email_elements = driver.find_elements(By.CLASS_NAME, 'gs_ai_eml')\n",
    "\n",
    "        candidates = []\n",
    "        max_index = None\n",
    "        max_similarity = 0\n",
    "        for i in range(len(dsc_elements)):\n",
    "            if 'ntu.edu.sg' in email_elements[i].text or 'Nanyang Technological University' in dsc_elements[i].text:\n",
    "                cur_name = driver.find_elements(By.CLASS_NAME, 'gs_ai_name')[i].text\n",
    "                # Similarity score of at least 80 before we consider it a match\n",
    "                sim_score = fuzz.token_sort_ratio(name,cur_name)\n",
    "                if sim_score>=80:\n",
    "                    author_url = driver.find_elements(By.CLASS_NAME, 'gs_ai_name')[i].find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                    candidates.append((cur_name,author_url))\n",
    "                    if len(candidates)==1:\n",
    "                        max_index=0\n",
    "                        max_similarity = sim_score\n",
    "                    elif sim_score>max_similarity:\n",
    "                        max_index = len(candidates)-1\n",
    "                        max_similarity = sim_score\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "        driver.quit()\n",
    "\n",
    "        if max_index != None:\n",
    "            candidate = candidates[max_index]\n",
    "            cur_name = candidate[0]\n",
    "            author_url = candidate[1]\n",
    "            prof_result['goog_sch_url'] = author_url\n",
    "            driver = create_driver()\n",
    "            driver.get(author_url+\"&pagesize=100\")\n",
    "            time.sleep(3)  # wait for the page to load\n",
    "            \n",
    "            # extract name\n",
    "            prof_result['name'] = author_full_name\n",
    "\n",
    "            list_of_interests = []\n",
    "            try:\n",
    "                # extracting interests\n",
    "                int_element = driver.find_elements(By.ID, 'gsc_prf_int')\n",
    "                if len(int_element)>0:\n",
    "                    int_element = int_element[0]\n",
    "                    a_tags = int_element.find_elements(By.TAG_NAME, 'a')\n",
    "                    list_of_interests = [tag.text for tag in a_tags]\n",
    "                else:\n",
    "                    pass\n",
    "            except Exception as e:\n",
    "                print(f\"Error Interest List for {author_full_name}\")\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "            prof_result['interests'] = list_of_interests\n",
    "\n",
    "\n",
    "            # extracting co_authors_url\n",
    "            co_authors_details = []\n",
    "\n",
    "            # some prof dont have co_authors\n",
    "            try:\n",
    "                co_author_table = driver.find_elements(By.ID,'gsc_rsb_co')\n",
    "                if len(co_author_table)==0:\n",
    "                    pass\n",
    "                else:\n",
    "                    co_author_table = co_author_table[0]\n",
    "\n",
    "                    co_author_view_btn = driver.find_elements(By.ID,'gsc_coauth_opn')\n",
    "                    if len(co_author_view_btn)>0:\n",
    "                        open_btn = co_author_view_btn[0]\n",
    "                        open_btn.click()\n",
    "                        time.sleep(4)\n",
    "\n",
    "                        content = driver.find_element(By.ID,'gsc_codb_content').get_attribute('outerHTML')\n",
    "                        soup = BeautifulSoup(content,'html.parser')\n",
    "                        co_authors_list = soup.find_all(name='div', attrs={'class':'gsc_ucoar gs_scl'})\n",
    "\n",
    "                        for co_author in co_authors_list:\n",
    "                            desc = co_author.find(name='div', attrs={'class':'gs_ai_t gs_ai_pss'})\n",
    "                            name_div = desc.find(name='h3', attrs={'class': 'gs_ai_name'})\n",
    "                            name = name_div.text.strip()\n",
    "                            url = name_div.find(name='a').get('href')\n",
    "                            aff = desc.find(name='div', attrs={'class':'gs_ai_aff'}).text.strip()\n",
    "                            \n",
    "                            co_authors_details.append({\n",
    "                                'name':name,\n",
    "                                'url': BASE_URL + url,\n",
    "                                'aff':aff\n",
    "                            })\n",
    "\n",
    "                        close_button = driver.find_element(By.ID,'gsc_md_cod-x')\n",
    "                        close_button.click()\n",
    "                    else:\n",
    "                        co_authors_list = co_author_table.find_element(By.CLASS_NAME,'gsc_rsb_a').find_elements(By.TAG_NAME,'li')\n",
    "                        for co_author in co_authors_list:\n",
    "                            name = co_author.find_element(By.CLASS_NAME,'gsc_rsb_a_desc').find_element(By.TAG_NAME,'a').text\n",
    "                            url = co_author.find_element(By.CLASS_NAME,'gsc_rsb_a_desc').find_element(By.TAG_NAME,'a').get_attribute('href')\n",
    "                            aff = co_author.find_element(By.CLASS_NAME,'gsc_rsb_a_ext').text\n",
    "                                \n",
    "                            co_authors_details.append({\n",
    "                                'name':name,\n",
    "                                'url': url,\n",
    "                                'aff':aff\n",
    "                            })\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in Co-Authors Table for {author_full_name}\")\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "            prof_result['co_authors_url'] = co_authors_details\n",
    "            \n",
    "            prof_result['citation_table'] = {}\n",
    "            try:\n",
    "                # extracting citation table info\n",
    "                cols = []\n",
    "                ths = driver.find_element(By.ID, 'gsc_rsb_st').find_element(By.TAG_NAME,'thead').find_elements(By.CLASS_NAME,'gsc_rsb_sth')\n",
    "                for th in ths:\n",
    "                    if th.text!=\"\":\n",
    "                        cols.append(th.text)\n",
    "\n",
    "                prof_result['citation_table']['columns'] = cols\n",
    "                \n",
    "                trs = driver.find_element(By.ID, 'gsc_rsb_st').find_element(By.TAG_NAME, 'tbody').find_elements(By.TAG_NAME, 'tr')\n",
    "                for tr in trs:\n",
    "                    row_index = tr.find_element(By.CLASS_NAME,'gsc_rsb_sc1').text\n",
    "                    counts = [int(count.text) for count in tr.find_elements(By.CLASS_NAME,'gsc_rsb_std')]\n",
    "                    prof_result['citation_table'][row_index] = counts\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in Citation Table for {author_full_name}\") \n",
    "                print(e)\n",
    "\n",
    "            citation_graph = {}\n",
    "            try:\n",
    "                view_char_btn = driver.find_elements(By.ID, 'gsc_hist_opn')\n",
    "                if len(view_char_btn)>0:\n",
    "                    \n",
    "                    view_char_btn[0].click()\n",
    "                    time.sleep(3)\n",
    "\n",
    "                    graph = driver.find_element(By.ID,'gsc_md_hist_c').find_element(By.CLASS_NAME,'gsc_md_hist_b')\n",
    "                    years = graph.find_elements(By.CLASS_NAME,'gsc_g_t')\n",
    "                    citation_counts = graph.find_elements(By.CLASS_NAME,'gsc_g_a')\n",
    "\n",
    "                    for i in range(len(citation_counts)):\n",
    "                        style = citation_counts[i].get_attribute('style')\n",
    "                        year_index = int(style.split(':')[-1].strip(';'))\n",
    "                        citation_graph[int(years[-year_index].get_attribute('innerText'))] = int(citation_counts[i].get_attribute('textContent'))\n",
    "                    close_chart_btn = driver.find_element(By.ID,'gsc_md_hist-x')\n",
    "                    close_chart_btn.click()\n",
    "       \n",
    "            except Exception as e:\n",
    "                print(f\"Error in citation graph for {author_full_name}\")\n",
    "                print(e)\n",
    "\n",
    "            prof_result['citation_graph'] = citation_graph\n",
    "\n",
    "            articles = []\n",
    "            try:\n",
    "                # extracting articles info\n",
    "                btn = driver.find_element(By.ID,'gsc_bpf_more')\n",
    "                while btn.get_attribute('disabled') is None:\n",
    "                    btn.click()\n",
    "                    time.sleep(3)\n",
    "\n",
    "                article_url_list = []\n",
    "                trs = driver.find_element(By.ID, 'gsc_a_b').find_elements(By.CLASS_NAME, 'gsc_a_tr')\n",
    "                for tr in trs:\n",
    "                    \n",
    "                    article_url_list.append(tr.find_element(By.CLASS_NAME,'gsc_a_t').find_element(By.TAG_NAME,'a').get_attribute('href'))\n",
    "                    \n",
    "                driver.quit()\n",
    "\n",
    "                for article_url in tqdm(article_url_list,position=0,leave=True):\n",
    "                    driver = create_driver()\n",
    "                    driver.get(article_url)\n",
    "                    time.sleep(3)\n",
    "                    title = driver.find_element(By.ID, 'gsc_oci_title').text\n",
    "                    items = driver.find_element(By.ID, 'gsc_oci_table').find_elements(By.CLASS_NAME, 'gs_scl')\n",
    "\n",
    "                    article = {}\n",
    "                    article['title'] = title\n",
    "                    article['url'] = article_url\n",
    "                    for item in items:\n",
    "                        key = item.find_element(By.CLASS_NAME, 'gsc_oci_field')\n",
    "                        value = item.find_element(By.CLASS_NAME, 'gsc_oci_value')\n",
    "                        key = key.text.strip().lower().replace(' ', '_')\n",
    "                        if key =='authors':\n",
    "                            article[key] = value.text.split(', ')\n",
    "                        if key=='publication_date':\n",
    "                            article[key] = value.text\n",
    "                        if key=='journal' or key=='book' or key=='conference':\n",
    "                            article[key] = value.text\n",
    "                        if key=='description':\n",
    "                            article[key]= value.text\n",
    "                        if key=='total_citations':\n",
    "                            # total citation count\n",
    "                            article[key] = int(value.find_element(By.TAG_NAME, 'a').text.split(' ')[-1])\n",
    "\n",
    "                            # citation count over the years\n",
    "                            years = value.find_elements(By.CLASS_NAME,'gsc_oci_g_t')\n",
    "                            citations = value.find_elements(By.CLASS_NAME,'gsc_oci_g_a')\n",
    "                            value_2 = {int(year.get_attribute('innerText')):0 for year in years}\n",
    "                            for citation in citations:\n",
    "                                year = int(citation.get_attribute('href')[-4:])\n",
    "                                value_2[year] = int(citation.get_attribute('textContent'))\n",
    "                            article['citation_graph'] = value_2\n",
    "                    articles.append(article)\n",
    "                    driver.quit()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in Articles for {author_full_name}\")\n",
    "                print(e)\n",
    "            prof_result['articles'] = articles\n",
    "            \n",
    "        # No need to search through all name_permutations as best candidate has been found\n",
    "        if max_index != None:\n",
    "            break\n",
    "        \n",
    "    filename = \"goog_sch_\"+author_full_name.lower().replace(' ','_')+'.json'\n",
    "    save_prof_details(details=prof_result,filename=filename)\n",
    "                \n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv('./prof_raw_data/scse_profiles.csv')\n",
    "result_df = result_df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['Name'].apply(extract_goog_sch_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilbometric\n",
    "\n",
    "- For the remaining professor that were not found through name search, we check if we manage to scrape their google scholar url from DR-NTU bilbometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_author = ['Miao Chun Yan','Li Boyang','Li Mo','Chan Syin','Josephine Chong','Lau Chiew Tong','Li Fang','Pan, Sinno Jialin','Tang Xueyan','Tay Kian Boon','Thambipillai Srikanthan','Vun Chan Hua Nicholas','Wee Keong Ng','Zinovi Rabinovich']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://scholar.google.com'\n",
    "\n",
    "for name in missing_author:\n",
    "    filename = name.lower().replace(' ','_')\n",
    "    filepath = f\"./prof_raw_data/dr_ntu_{filename}.json\"\n",
    "    with open(filepath,'r') as f:\n",
    "        author = json.load(f)\n",
    "    prof_result = {}\n",
    "    if 'google_scholar' in author['urls']:\n",
    "        if author['urls']['google_scholar']:\n",
    "            driver = create_driver()\n",
    "            driver.get(author['urls']['google_scholar']+\"&pagesize=100\")\n",
    "            time.sleep(3)  # wait for the page to load\n",
    "            \n",
    "            # extract name\n",
    "            prof_result['goog_sch_url'] = author['urls']['google_scholar']\n",
    "            prof_result['name'] = name\n",
    "\n",
    "            list_of_interests = []\n",
    "            try:\n",
    "                # extracting interests\n",
    "                int_element = driver.find_elements(By.ID, 'gsc_prf_int')\n",
    "                if len(int_element)>0:\n",
    "                    int_element = int_element[0]\n",
    "                    a_tags = int_element.find_elements(By.TAG_NAME, 'a')\n",
    "                    list_of_interests = [tag.text for tag in a_tags]\n",
    "                else:\n",
    "                    pass\n",
    "            except Exception as e:\n",
    "                print(f\"Error Interest List for {name}\")\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "            prof_result['interests'] = list_of_interests\n",
    "\n",
    "\n",
    "            # extracting co_authors_url\n",
    "            co_authors_details = []\n",
    "\n",
    "            # some prof dont have co_authors\n",
    "            try:\n",
    "                co_author_table = driver.find_elements(By.ID,'gsc_rsb_co')\n",
    "                if len(co_author_table)==0:\n",
    "                    pass\n",
    "                else:\n",
    "                    co_author_table = co_author_table[0]\n",
    "\n",
    "                    co_author_view_btn = driver.find_elements(By.ID,'gsc_coauth_opn')\n",
    "                    if len(co_author_view_btn)>0:\n",
    "                        open_btn = co_author_view_btn[0]\n",
    "                        open_btn.click()\n",
    "                        time.sleep(4)\n",
    "\n",
    "                        content = driver.find_element(By.ID,'gsc_codb_content').get_attribute('outerHTML')\n",
    "                        soup = BeautifulSoup(content,'html.parser')\n",
    "                        co_authors_list = soup.find_all(name='div', attrs={'class':'gsc_ucoar gs_scl'})\n",
    "\n",
    "                        for co_author in co_authors_list:\n",
    "                            desc = co_author.find(name='div', attrs={'class':'gs_ai_t gs_ai_pss'})\n",
    "                            name_div = desc.find(name='h3', attrs={'class': 'gs_ai_name'})\n",
    "                            name = name_div.text.strip()\n",
    "                            url = name_div.find(name='a').get('href')\n",
    "                            aff = desc.find(name='div', attrs={'class':'gs_ai_aff'}).text.strip()\n",
    "                            \n",
    "                            co_authors_details.append({\n",
    "                                'name':name,\n",
    "                                'url': BASE_URL + url,\n",
    "                                'aff':aff\n",
    "                            })\n",
    "\n",
    "                        close_button = driver.find_element(By.ID,'gsc_md_cod-x')\n",
    "                        close_button.click()\n",
    "                    else:\n",
    "                        co_authors_list = co_author_table.find_element(By.CLASS_NAME,'gsc_rsb_a').find_elements(By.TAG_NAME,'li')\n",
    "                        for co_author in co_authors_list:\n",
    "                            name = co_author.find_element(By.CLASS_NAME,'gsc_rsb_a_desc').find_element(By.TAG_NAME,'a').text\n",
    "                            url = co_author.find_element(By.CLASS_NAME,'gsc_rsb_a_desc').find_element(By.TAG_NAME,'a').get_attribute('href')\n",
    "                            aff = co_author.find_element(By.CLASS_NAME,'gsc_rsb_a_ext').text\n",
    "                                \n",
    "                            co_authors_details.append({\n",
    "                                'name':name,\n",
    "                                'url': url,\n",
    "                                'aff':aff\n",
    "                            })\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in Co-Authors Table for {name}\")\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "            prof_result['co_authors_url'] = co_authors_details\n",
    "            \n",
    "            prof_result['citation_table'] = {}\n",
    "            try:\n",
    "                # extracting citation table info\n",
    "                cols = []\n",
    "                ths = driver.find_element(By.ID, 'gsc_rsb_st').find_element(By.TAG_NAME,'thead').find_elements(By.CLASS_NAME,'gsc_rsb_sth')\n",
    "                for th in ths:\n",
    "                    if th.text!=\"\":\n",
    "                        cols.append(th.text)\n",
    "\n",
    "                prof_result['citation_table']['columns'] = cols\n",
    "                \n",
    "                trs = driver.find_element(By.ID, 'gsc_rsb_st').find_element(By.TAG_NAME, 'tbody').find_elements(By.TAG_NAME, 'tr')\n",
    "                for tr in trs:\n",
    "                    row_index = tr.find_element(By.CLASS_NAME,'gsc_rsb_sc1').text\n",
    "                    counts = [int(count.text) for count in tr.find_elements(By.CLASS_NAME,'gsc_rsb_std')]\n",
    "                    prof_result['citation_table'][row_index] = counts\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in Citation Table for {name}\") \n",
    "                print(e)\n",
    "\n",
    "            citation_graph = {}\n",
    "            try:\n",
    "                view_char_btn = driver.find_elements(By.ID, 'gsc_hist_opn')\n",
    "                if len(view_char_btn)>0:\n",
    "                    \n",
    "                    view_char_btn[0].click()\n",
    "                    time.sleep(3)\n",
    "\n",
    "                    graph = driver.find_element(By.ID,'gsc_md_hist_c').find_element(By.CLASS_NAME,'gsc_md_hist_b')\n",
    "                    years = graph.find_elements(By.CLASS_NAME,'gsc_g_t')\n",
    "                    citation_counts = graph.find_elements(By.CLASS_NAME,'gsc_g_a')\n",
    "\n",
    "                    for i in range(len(citation_counts)):\n",
    "                        style = citation_counts[i].get_attribute('style')\n",
    "                        year_index = int(style.split(':')[-1].strip(';'))\n",
    "                        citation_graph[int(years[-year_index].get_attribute('innerText'))] = int(citation_counts[i].get_attribute('textContent'))\n",
    "                    close_chart_btn = driver.find_element(By.ID,'gsc_md_hist-x')\n",
    "                    close_chart_btn.click()\n",
    "       \n",
    "            except Exception as e:\n",
    "                print(f\"Error in citation graph for {name}\")\n",
    "                print(e)\n",
    "\n",
    "            prof_result['citation_graph'] = citation_graph\n",
    "\n",
    "            articles = []\n",
    "            try:\n",
    "                # extracting articles info\n",
    "                btn = driver.find_element(By.ID,'gsc_bpf_more')\n",
    "                while btn.get_attribute('disabled') is None:\n",
    "                    btn.click()\n",
    "                    time.sleep(3)\n",
    "\n",
    "                article_url_list = []\n",
    "                trs = driver.find_element(By.ID, 'gsc_a_b').find_elements(By.CLASS_NAME, 'gsc_a_tr')\n",
    "                for tr in trs:\n",
    "                    \n",
    "                    article_url_list.append(tr.find_element(By.CLASS_NAME,'gsc_a_t').find_element(By.TAG_NAME,'a').get_attribute('href'))\n",
    "                    \n",
    "                driver.quit()\n",
    "\n",
    "                for article_url in tqdm(article_url_list,position=0,leave=True):\n",
    "                    driver = create_driver()\n",
    "                    driver.get(article_url)\n",
    "                    time.sleep(3)\n",
    "                    title = driver.find_element(By.ID, 'gsc_oci_title').text\n",
    "                    items = driver.find_element(By.ID, 'gsc_oci_table').find_elements(By.CLASS_NAME, 'gs_scl')\n",
    "\n",
    "                    article = {}\n",
    "                    article['title'] = title\n",
    "                    article['url'] = article_url\n",
    "                    for item in items:\n",
    "                        key = item.find_element(By.CLASS_NAME, 'gsc_oci_field')\n",
    "                        value = item.find_element(By.CLASS_NAME, 'gsc_oci_value')\n",
    "                        key = key.text.strip().lower().replace(' ', '_')\n",
    "                        if key =='authors':\n",
    "                            article[key] = value.text.split(', ')\n",
    "                        if key=='publication_date':\n",
    "                            article[key] = value.text\n",
    "                        if key=='journal' or key=='book' or key=='conference':\n",
    "                            article[key] = value.text\n",
    "                        if key=='description':\n",
    "                            article[key]= value.text\n",
    "                        if key=='total_citations':\n",
    "                            # total citation count\n",
    "                            article[key] = int(value.find_element(By.TAG_NAME, 'a').text.split(' ')[-1])\n",
    "\n",
    "                            # citation count over the years\n",
    "                            years = value.find_elements(By.CLASS_NAME,'gsc_oci_g_t')\n",
    "                            citations = value.find_elements(By.CLASS_NAME,'gsc_oci_g_a')\n",
    "                            value_2 = {int(year.get_attribute('innerText')):0 for year in years}\n",
    "                            for citation in citations:\n",
    "                                year = int(citation.get_attribute('href')[-4:])\n",
    "                                value_2[year] = int(citation.get_attribute('textContent'))\n",
    "                            article['citation_graph'] = value_2\n",
    "                    articles.append(article)\n",
    "                    driver.quit()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in Articles for {name}\")\n",
    "                print(e)\n",
    "            prof_result['articles'] = articles\n",
    "    save_prof_details(prof_result,filename=f\"goog_sch_{filename}.json\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Additional Co-Author Details\n",
    "\n",
    "- Created to extract additional details from Google Scholar that is needed to build up the dashboard co-author features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './prof_raw_data/'\n",
    "goog_sch_file_list = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f)) and 'goog_sch' in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_file_path = ['./prof_raw_data/goog_sch_miao_chun_yan.json','./prof_raw_data/goog_sch_li_boyang.json','./prof_raw_data/goog_sch_li_mo.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [09:21<00:00,  9.51s/it]\n",
      "100%|██████████| 22/22 [03:24<00:00,  9.30s/it]\n",
      "100%|██████████| 13/13 [01:42<00:00,  7.91s/it]\n",
      "100%|██████████| 32/32 [05:03<00:00,  9.49s/it]\n",
      "100%|██████████| 43/43 [06:42<00:00,  9.35s/it]\n",
      "100%|██████████| 166/166 [24:10<00:00,  8.74s/it]\n",
      "100%|██████████| 12/12 [02:02<00:00, 10.20s/it]\n",
      "100%|██████████| 10/10 [01:48<00:00, 10.87s/it]\n",
      "100%|██████████| 51/51 [08:23<00:00,  9.86s/it]\n",
      "100%|██████████| 16/16 [02:42<00:00, 10.15s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 51/51 [08:13<00:00,  9.67s/it]\n",
      "100%|██████████| 35/35 [04:59<00:00,  8.54s/it]\n",
      "100%|██████████| 14/14 [01:55<00:00,  8.25s/it]\n",
      "100%|██████████| 32/32 [04:09<00:00,  7.78s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 39/39 [05:35<00:00,  8.60s/it]\n",
      "100%|██████████| 17/17 [02:35<00:00,  9.17s/it]\n",
      "100%|██████████| 13/13 [02:06<00:00,  9.72s/it]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 16/16 [02:51<00:00, 10.74s/it]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.22s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 18/18 [03:08<00:00, 10.49s/it]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 66/66 [10:21<00:00,  9.41s/it]\n",
      "100%|██████████| 35/35 [04:55<00:00,  8.45s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 8/8 [01:19<00:00,  9.88s/it]\n",
      "100%|██████████| 30/30 [04:47<00:00,  9.60s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 41/41 [06:32<00:00,  9.58s/it]\n",
      "100%|██████████| 13/13 [02:02<00:00,  9.45s/it]\n",
      "100%|██████████| 6/6 [01:03<00:00, 10.62s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 35/35 [05:24<00:00,  9.28s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 15/15 [02:34<00:00, 10.32s/it]\n",
      "100%|██████████| 46/46 [07:26<00:00,  9.70s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 92/92 [14:04<00:00,  9.18s/it]\n",
      "100%|██████████| 22/22 [03:07<00:00,  8.50s/it]\n",
      "100%|██████████| 176/176 [27:54<00:00,  9.52s/it]\n",
      " 93%|█████████▎| 168/180 [25:26<01:36,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in Citation Table for main author:Chen Change Loy, co_author:Yuxin Jiang\n",
      "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"gsc_rsb_st\"]\"}\n",
      "  (Session info: headless chrome=118.0.5993.117); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001071e6e08 chromedriver + 5025288\n",
      "1   chromedriver                        0x00000001071ddc23 chromedriver + 4987939\n",
      "2   chromedriver                        0x0000000106d7fe67 chromedriver + 409191\n",
      "3   chromedriver                        0x0000000106dcf1b9 chromedriver + 733625\n",
      "4   chromedriver                        0x0000000106dcf371 chromedriver + 734065\n",
      "5   chromedriver                        0x0000000106e15194 chromedriver + 1020308\n",
      "6   chromedriver                        0x0000000106df650d chromedriver + 894221\n",
      "7   chromedriver                        0x0000000106e12571 chromedriver + 1009009\n",
      "8   chromedriver                        0x0000000106df62b3 chromedriver + 893619\n",
      "9   chromedriver                        0x0000000106dc0eb9 chromedriver + 675513\n",
      "10  chromedriver                        0x0000000106dc20ee chromedriver + 680174\n",
      "11  chromedriver                        0x00000001071a8819 chromedriver + 4769817\n",
      "12  chromedriver                        0x00000001071ad893 chromedriver + 4790419\n",
      "13  chromedriver                        0x00000001071b466e chromedriver + 4818542\n",
      "14  chromedriver                        0x00000001071ae5bd chromedriver + 4793789\n",
      "15  chromedriver                        0x000000010718098c chromedriver + 4606348\n",
      "16  chromedriver                        0x00000001071ccb78 chromedriver + 4918136\n",
      "17  chromedriver                        0x00000001071ccd30 chromedriver + 4918576\n",
      "18  chromedriver                        0x00000001071dd85e chromedriver + 4986974\n",
      "19  libsystem_pthread.dylib             0x00007ff81b9b8202 _pthread_start + 99\n",
      "20  libsystem_pthread.dylib             0x00007ff81b9b3bab thread_start + 15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 174/180 [26:21<00:51,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in Citation Table for main author:Chen Change Loy, co_author:Wayne Wu\n",
      "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"gsc_rsb_st\"]\"}\n",
      "  (Session info: headless chrome=118.0.5993.117); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000104ba7e08 chromedriver + 5025288\n",
      "1   chromedriver                        0x0000000104b9ec23 chromedriver + 4987939\n",
      "2   chromedriver                        0x0000000104740e67 chromedriver + 409191\n",
      "3   chromedriver                        0x00000001047901b9 chromedriver + 733625\n",
      "4   chromedriver                        0x0000000104790371 chromedriver + 734065\n",
      "5   chromedriver                        0x00000001047d6194 chromedriver + 1020308\n",
      "6   chromedriver                        0x00000001047b750d chromedriver + 894221\n",
      "7   chromedriver                        0x00000001047d3571 chromedriver + 1009009\n",
      "8   chromedriver                        0x00000001047b72b3 chromedriver + 893619\n",
      "9   chromedriver                        0x0000000104781eb9 chromedriver + 675513\n",
      "10  chromedriver                        0x00000001047830ee chromedriver + 680174\n",
      "11  chromedriver                        0x0000000104b69819 chromedriver + 4769817\n",
      "12  chromedriver                        0x0000000104b6e893 chromedriver + 4790419\n",
      "13  chromedriver                        0x0000000104b7566e chromedriver + 4818542\n",
      "14  chromedriver                        0x0000000104b6f5bd chromedriver + 4793789\n",
      "15  chromedriver                        0x0000000104b4198c chromedriver + 4606348\n",
      "16  chromedriver                        0x0000000104b8db78 chromedriver + 4918136\n",
      "17  chromedriver                        0x0000000104b8dd30 chromedriver + 4918576\n",
      "18  chromedriver                        0x0000000104b9e85e chromedriver + 4986974\n",
      "19  libsystem_pthread.dylib             0x00007ff81b9b8202 _pthread_start + 99\n",
      "20  libsystem_pthread.dylib             0x00007ff81b9b3bab thread_start + 15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [27:21<00:00,  9.12s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 36/36 [05:05<00:00,  8.48s/it]\n",
      "100%|██████████| 37/37 [05:07<00:00,  8.30s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 45/45 [06:22<00:00,  8.50s/it]\n",
      "100%|██████████| 18/18 [02:47<00:00,  9.32s/it]\n",
      "100%|██████████| 48/48 [07:13<00:00,  9.02s/it]\n",
      "100%|██████████| 4/4 [00:35<00:00,  8.79s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 189/189 [28:05<00:00,  8.92s/it]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 136/136 [20:23<00:00,  9.00s/it]\n",
      "100%|██████████| 4/4 [00:33<00:00,  8.32s/it]\n",
      "100%|██████████| 45/45 [07:38<00:00, 10.19s/it]\n",
      "100%|██████████| 80/80 [12:11<00:00,  9.14s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 13/13 [02:05<00:00,  9.65s/it]\n",
      "100%|██████████| 188/188 [30:18<00:00,  9.67s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 9/9 [01:09<00:00,  7.75s/it]\n",
      "100%|██████████| 19/19 [03:21<00:00, 10.58s/it]\n",
      "100%|██████████| 70/70 [11:23<00:00,  9.76s/it]\n",
      "100%|██████████| 27/27 [04:14<00:00,  9.42s/it]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "co_author_dir = './co_author_data/'\n",
    "BASE_URL = 'https://scholar.google.com/'\n",
    "for filepath in goog_sch_file_list:\n",
    "    filename = filepath[25:-5]\n",
    "    with open(filepath,'r') as f:\n",
    "        profile = json.load(f)\n",
    "\n",
    "    co_author_network = {}\n",
    "    if 'co_authors_url' in profile:\n",
    "        author_url = profile['goog_sch_url']\n",
    "        co_author_network[author_url] = []\n",
    "\n",
    "        for co_author in tqdm(profile['co_authors_url'],position=0,leave=True):\n",
    "            co_author_url = co_author['url']\n",
    "            co_author_network[author_url].append(co_author_url)\n",
    "            co_author_network[co_author_url] = []\n",
    "\n",
    "            driver = create_driver()\n",
    "            driver.get(co_author_url)\n",
    "            time.sleep(3)  # wait for the page to load\n",
    "\n",
    "\n",
    "            co_author['citation_table'] = {}\n",
    "            try:\n",
    "                # extracting citation table info\n",
    "                cols = []\n",
    "                ths = driver.find_element(By.ID, 'gsc_rsb_st').find_element(By.TAG_NAME,'thead').find_elements(By.CLASS_NAME,'gsc_rsb_sth')\n",
    "                for th in ths:\n",
    "                    if th.text!=\"\":\n",
    "                        cols.append(th.text)\n",
    "\n",
    "                co_author['citation_table']['columns'] = cols\n",
    "                \n",
    "                trs = driver.find_element(By.ID, 'gsc_rsb_st').find_element(By.TAG_NAME, 'tbody').find_elements(By.TAG_NAME, 'tr')\n",
    "                for tr in trs:\n",
    "                    row_index = tr.find_element(By.CLASS_NAME,'gsc_rsb_sc1').text\n",
    "                    counts = [int(count.text) for count in tr.find_elements(By.CLASS_NAME,'gsc_rsb_std')]\n",
    "                    co_author['citation_table'][row_index] = counts\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in Citation Table for main author:{profile['name']}, co_author:{co_author['name']}\") \n",
    "                print(e)\n",
    "\n",
    "\n",
    "            # some prof dont have co_authors\n",
    "            try:\n",
    "                co_co_author_table = driver.find_elements(By.ID,'gsc_rsb_co')\n",
    "                if len(co_co_author_table)==0:\n",
    "                    pass\n",
    "                else:\n",
    "                    co_co_author_table = co_co_author_table[0]\n",
    "\n",
    "                    co_co_author_view_btn = driver.find_elements(By.ID,'gsc_coauth_opn')\n",
    "                    if len(co_co_author_view_btn)>0:\n",
    "                        open_btn = co_co_author_view_btn[0]\n",
    "                        open_btn.click()\n",
    "                        time.sleep(4)\n",
    "\n",
    "                        content = driver.find_element(By.ID,'gsc_codb_content').get_attribute('outerHTML')\n",
    "                        soup = BeautifulSoup(content,'html.parser')\n",
    "                        co_co_authors_list = soup.find_all(name='div', attrs={'class':'gsc_ucoar gs_scl'})\n",
    "\n",
    "                        for co_co_author in co_co_authors_list:\n",
    "                            desc = co_co_author.find(name='div', attrs={'class':'gs_ai_t gs_ai_pss'})\n",
    "                            name_div = desc.find(name='h3', attrs={'class': 'gs_ai_name'})\n",
    "                            co_co_author_url = name_div.find(name='a').get('href')\n",
    "                            \n",
    "                            co_author_network[co_author_url].append(BASE_URL + co_co_author_url)\n",
    "\n",
    "                        close_button = driver.find_element(By.ID,'gsc_md_cod-x')\n",
    "                        close_button.click()\n",
    "                    else:\n",
    "                        co_co_authors_list = co_co_author_table.find_element(By.CLASS_NAME,'gsc_rsb_a').find_elements(By.TAG_NAME,'li')\n",
    "                        for co_co_author in co_co_authors_list:\n",
    "                            co_co_author_url = co_co_author.find_element(By.CLASS_NAME,'gsc_rsb_a_desc').find_element(By.TAG_NAME,'a').get_attribute('href')\n",
    "                                \n",
    "                            co_author_network[co_author_url].append(co_co_author_url)\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in Co-Co-Authors Table for Co-Author {co_author['name']}\")\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "            driver.quit()\n",
    "        with open(filepath,'w') as f:\n",
    "            json.dump(profile,f)\n",
    "        \n",
    "    with open(f\"{co_author_dir}{filename}.json\",'w') as f:\n",
    "        json.dump(co_author_network,f)\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [05:57<00:00,  9.41s/it]\n",
      " 75%|███████▌  | 21/28 [03:41<01:19, 11.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in Co-Co-Authors Table for Co-Author Yangfeng Ji\n",
      "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"gsc_codb_content\"]\"}\n",
      "  (Session info: headless chrome=118.0.5993.117); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000107477e08 chromedriver + 5025288\n",
      "1   chromedriver                        0x000000010746ec23 chromedriver + 4987939\n",
      "2   chromedriver                        0x0000000107010e67 chromedriver + 409191\n",
      "3   chromedriver                        0x00000001070601b9 chromedriver + 733625\n",
      "4   chromedriver                        0x0000000107060371 chromedriver + 734065\n",
      "5   chromedriver                        0x00000001070a6194 chromedriver + 1020308\n",
      "6   chromedriver                        0x000000010708750d chromedriver + 894221\n",
      "7   chromedriver                        0x00000001070a3571 chromedriver + 1009009\n",
      "8   chromedriver                        0x00000001070872b3 chromedriver + 893619\n",
      "9   chromedriver                        0x0000000107051eb9 chromedriver + 675513\n",
      "10  chromedriver                        0x00000001070530ee chromedriver + 680174\n",
      "11  chromedriver                        0x0000000107439819 chromedriver + 4769817\n",
      "12  chromedriver                        0x000000010743e893 chromedriver + 4790419\n",
      "13  chromedriver                        0x000000010744566e chromedriver + 4818542\n",
      "14  chromedriver                        0x000000010743f5bd chromedriver + 4793789\n",
      "15  chromedriver                        0x000000010741198c chromedriver + 4606348\n",
      "16  chromedriver                        0x000000010745db78 chromedriver + 4918136\n",
      "17  chromedriver                        0x000000010745dd30 chromedriver + 4918576\n",
      "18  chromedriver                        0x000000010746e85e chromedriver + 4986974\n",
      "19  libsystem_pthread.dylib             0x00007ff81b9b8202 _pthread_start + 99\n",
      "20  libsystem_pthread.dylib             0x00007ff81b9b3bab thread_start + 15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [05:00<00:00, 10.73s/it]\n",
      "100%|██████████| 25/25 [04:02<00:00,  9.69s/it]\n"
     ]
    }
   ],
   "source": [
    "for filepath in error_file_path:\n",
    "    filename = filepath[25:-5]\n",
    "    with open(filepath,'r') as f:\n",
    "        profile = json.load(f)\n",
    "\n",
    "    co_author_network = {}\n",
    "    if 'co_authors_url' in profile:\n",
    "        author_url = profile['goog_sch_url']\n",
    "        co_author_network[author_url] = []\n",
    "\n",
    "        for co_author in tqdm(profile['co_authors_url'],position=0,leave=True):\n",
    "            co_author_url = co_author['url']\n",
    "            co_author_network[author_url].append(co_author_url)\n",
    "            co_author_network[co_author_url] = []\n",
    "\n",
    "            driver = create_driver()\n",
    "            driver.get(co_author_url)\n",
    "            time.sleep(3)  # wait for the page to load\n",
    "\n",
    "\n",
    "            co_author['citation_table'] = {}\n",
    "            try:\n",
    "                # extracting citation table info\n",
    "                cols = []\n",
    "                ths = driver.find_element(By.ID, 'gsc_rsb_st').find_element(By.TAG_NAME,'thead').find_elements(By.CLASS_NAME,'gsc_rsb_sth')\n",
    "                for th in ths:\n",
    "                    if th.text!=\"\":\n",
    "                        cols.append(th.text)\n",
    "\n",
    "                co_author['citation_table']['columns'] = cols\n",
    "                \n",
    "                trs = driver.find_element(By.ID, 'gsc_rsb_st').find_element(By.TAG_NAME, 'tbody').find_elements(By.TAG_NAME, 'tr')\n",
    "                for tr in trs:\n",
    "                    row_index = tr.find_element(By.CLASS_NAME,'gsc_rsb_sc1').text\n",
    "                    counts = [int(count.text) for count in tr.find_elements(By.CLASS_NAME,'gsc_rsb_std')]\n",
    "                    co_author['citation_table'][row_index] = counts\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in Citation Table for main author:{profile['name']}, co_author:{co_author['name']}\") \n",
    "                print(e)\n",
    "\n",
    "\n",
    "            # some prof dont have co_authors\n",
    "            try:\n",
    "                co_co_author_table = driver.find_elements(By.ID,'gsc_rsb_co')\n",
    "                if len(co_co_author_table)==0:\n",
    "                    pass\n",
    "                else:\n",
    "                    co_co_author_table = co_co_author_table[0]\n",
    "\n",
    "                    co_co_author_view_btn = driver.find_elements(By.ID,'gsc_coauth_opn')\n",
    "                    if len(co_co_author_view_btn)>0:\n",
    "                        open_btn = co_co_author_view_btn[0]\n",
    "                        open_btn.click()\n",
    "                        time.sleep(4)\n",
    "\n",
    "                        content = driver.find_element(By.ID,'gsc_codb_content').get_attribute('outerHTML')\n",
    "                        soup = BeautifulSoup(content,'html.parser')\n",
    "                        co_co_authors_list = soup.find_all(name='div', attrs={'class':'gsc_ucoar gs_scl'})\n",
    "\n",
    "                        for co_co_author in co_co_authors_list:\n",
    "                            desc = co_co_author.find(name='div', attrs={'class':'gs_ai_t gs_ai_pss'})\n",
    "                            name_div = desc.find(name='h3', attrs={'class': 'gs_ai_name'})\n",
    "                            co_co_author_url = name_div.find(name='a').get('href')\n",
    "                            \n",
    "                            co_author_network[co_author_url].append(BASE_URL + co_co_author_url)\n",
    "\n",
    "                        close_button = driver.find_element(By.ID,'gsc_md_cod-x')\n",
    "                        close_button.click()\n",
    "                    else:\n",
    "                        co_co_authors_list = co_co_author_table.find_element(By.CLASS_NAME,'gsc_rsb_a').find_elements(By.TAG_NAME,'li')\n",
    "                        for co_co_author in co_co_authors_list:\n",
    "                            co_co_author_url = co_co_author.find_element(By.CLASS_NAME,'gsc_rsb_a_desc').find_element(By.TAG_NAME,'a').get_attribute('href')\n",
    "                                \n",
    "                            co_author_network[co_author_url].append(co_co_author_url)\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in Co-Co-Authors Table for Co-Author {co_author['name']}\")\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "            driver.quit()\n",
    "        with open(filepath,'w') as f:\n",
    "            json.dump(profile,f)\n",
    "        \n",
    "    with open(f\"{co_author_dir}{filename}.json\",'w') as f:\n",
    "        json.dump(co_author_network,f)\n",
    "\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CZ4125",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
