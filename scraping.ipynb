{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to Scrape\n",
    "\n",
    "1. Professor's Experience/Affiliation (DBLP) & Google Scholar URL --> Background info of researcher\n",
    "2. Description, Year, Venues of all Publications by invidivual (Google Scholar) --> Quantitative Metric & Track Shifts in Research Interest\n",
    "3. Collaboration counts and their citation counts for each co-authors(DBLP & Google Scholar) --> Create Coauthor Network Graph\n",
    "4. Scrape Conference/Journals Ratings (portal conference website)\n",
    "5. Scrape the research interest for each professor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import requests\n",
    "from thefuzz import fuzz\n",
    "import re\n",
    "import itertools\n",
    "from selenium import webdriver\n",
    "from selenium_stealth import stealth\n",
    "from selenium.webdriver.common.by import By\n",
    "import os,json\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.webdriver.support.expected_conditions import invisibility_of_element_located\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Google Scholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n    {\\n        \\'name\\': \"Li Boyang\",\\n        \\'interest\\': [\\'ML\\',\\'AI\\'],\\n        \\'articles\\':[\\n            {\\n                \\'Title\\': \"Story Generation\",\\n                \\'CO-Authors\\' : [\\'Mark Riedl\\',\\'LOL\\'],\\n                \\'date\\': str,\\n                \\'venue\\': str,\\n                \\'Description: str,\\n                \\'Cited by\\': int,\\n                \\'citation_graph\\':dict\\n            },\\n        ],\\n        \\'co_authors_profile_url\\': [\\n            \\'https://scholar.google.com/citations?user=Yg_QjxcAAAAJ&hl=en\\',\\n        ]\\n        \\'all_citation_count\\': int\\n        \\'recent_citation_count: int\\n        }\\n\\n\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "    {\n",
    "        'name': \"Li Boyang\",\n",
    "        'interest': ['ML','AI'],\n",
    "        'articles':[\n",
    "            {\n",
    "                'Title': \"Story Generation\",\n",
    "                'CO-Authors' : ['Mark Riedl','LOL'],\n",
    "                'date': str,\n",
    "                'venue': str,\n",
    "                'Description: str,\n",
    "                'Cited by': int,\n",
    "                'citation_graph':dict\n",
    "            },\n",
    "        ],\n",
    "        'co_authors_profile_url': [\n",
    "            'https://scholar.google.com/citations?user=Yg_QjxcAAAAJ&hl=en',\n",
    "        ]\n",
    "        'all_citation_count': int\n",
    "        'recent_citation_count: int\n",
    "        }\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scholarly Name Search\n",
    "\n",
    "- Add Nanyang Technological University as keyword during the search to narrow down the results\n",
    "- Disadvantage is that those faculty member which did not update their affiliation will be lost in this search\n",
    "- Hence we need to search by citation as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prof_details(details, filename, dir='./prof_raw_data'):\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    filename = dir + '/' + filename\n",
    "        \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(details, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name_combinations(name):\n",
    "    words = name.split()\n",
    "    combinations = []\n",
    "    for r in range(2, len(words) + 1):\n",
    "        combinations.extend(list(itertools.combinations(words, r)))\n",
    "    combinations = [' '.join(combination).strip(',') for combination in combinations]\n",
    "    return combinations[::-1]\n",
    "\n",
    "def create_driver(debug=False):\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    if debug==False:\n",
    "        options.add_argument(\"--headless\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    driver = webdriver.Chrome(\n",
    "        options=options\n",
    "    )\n",
    "    stealth(driver,\n",
    "            # user_agent=agent,\n",
    "            languages=[\"en-US\", \"en\"],\n",
    "            vendor=\"Google Inc.\",\n",
    "            platform=\"Win32\",\n",
    "            webgl_vendor=\"Intel Inc.\",\n",
    "            renderer=\"Intel Iris OpenGL Engine\",\n",
    "            fix_hairline=True,\n",
    "            )\n",
    "    return driver\n",
    "\n",
    "def scrape_goog_sch_profile(author_full_name):\n",
    "\n",
    "    # base_url = 'https://scholar.google.com'\n",
    "    if len(author_full_name.split())>2:\n",
    "        name_perm_list = generate_name_combinations(author_full_name)\n",
    "    else:\n",
    "        name_perm_list = [author_full_name]\n",
    "\n",
    "    prof_result = {}\n",
    "    for name in name_perm_list:\n",
    "        query_param = name+\" Nanyang Technological University\"\n",
    "        search_url = f\"https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors={query_param}&btnG=\"\n",
    "\n",
    "        driver = create_driver()\n",
    "        driver.get(search_url)\n",
    "        time.sleep(3)  # wait for the page to load\n",
    "\n",
    "        # find professors' descriptions and emails\n",
    "        dsc_elements = driver.find_elements(By.CLASS_NAME, 'gs_ai_aff') \n",
    "        email_elements = driver.find_elements(By.CLASS_NAME, 'gs_ai_eml')\n",
    "\n",
    "        candidates = []\n",
    "        max_index = None\n",
    "        max_similarity = 0\n",
    "        for i in range(len(dsc_elements)):\n",
    "            if 'ntu.edu.sg' in email_elements[i].text or 'Nanyang Technological University' in dsc_elements[i].text:\n",
    "                cur_name = driver.find_elements(By.CLASS_NAME, 'gs_ai_name')[i].text\n",
    "                # Similarity score of at least 80 before we consider it a match\n",
    "                sim_score = fuzz.token_sort_ratio(name,cur_name)\n",
    "                if sim_score>=80:\n",
    "                    author_url = driver.find_elements(By.CLASS_NAME, 'gs_ai_name')[i].find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                    candidates.append((cur_name,author_url))\n",
    "                    if len(candidates)==1:\n",
    "                        max_index=0\n",
    "                        max_similarity = sim_score\n",
    "                    elif sim_score>max_similarity:\n",
    "                        max_index = len(candidates)-1\n",
    "                        max_similarity = sim_score\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "        driver.quit()\n",
    "\n",
    "        if max_index != None:\n",
    "            candidate = candidates[max_index]\n",
    "            cur_name = candidate[0]\n",
    "            author_url = candidate[1]\n",
    "            prof_result['goog_sch_url'] = author_url\n",
    "            driver = create_driver()\n",
    "            driver.get(author_url+\"&pagesize=100\")\n",
    "            time.sleep(3)  # wait for the page to load\n",
    "            \n",
    "            # extract name\n",
    "            prof_result['name'] = author_full_name\n",
    "\n",
    "            list_of_interests = []\n",
    "            try:\n",
    "                # extracting interests\n",
    "                int_element = driver.find_elements(By.ID, 'gsc_prf_int')\n",
    "                if len(int_element)>0:\n",
    "                    int_element = int_element[0]\n",
    "                    a_tags = int_element.find_elements(By.TAG_NAME, 'a')\n",
    "                    list_of_interests = [tag.text for tag in a_tags]\n",
    "                else:\n",
    "                    pass\n",
    "            except Exception as e:\n",
    "                print(f\"Error Interest List for {author_full_name}\")\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "            prof_result['interests'] = list_of_interests\n",
    "\n",
    "\n",
    "            # extracting co_authors_url\n",
    "            co_authors_details = []\n",
    "\n",
    "            # some prof dont have co_authors\n",
    "            try:\n",
    "                co_author_table = driver.find_elements(By.ID,'gsc_rsb_co')\n",
    "                if len(co_author_table)==0:\n",
    "                    pass\n",
    "                else:\n",
    "                    co_author_table = co_author_table[0]\n",
    "\n",
    "                    co_author_view_btn = driver.find_elements(By.ID,'gsc_coauth_opn')\n",
    "                    if len(co_author_view_btn)>0:\n",
    "                        co_author_view_btn[0].click()\n",
    "                        time.sleep(3)\n",
    "\n",
    "                        co_authors_list = driver.find_element(By.ID,'gsc_codb_content').find_elements(By.CLASS_NAME,'gsc_ucoar gs_scl')\n",
    "                        \n",
    "                        for co_author in co_authors_list:\n",
    "                            name = co_author.find_element(By.CLASS_NAME,'gs_ai_name').find_element(By.TAG_NAME,'a').text\n",
    "                            url = co_author.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                            aff = co_author.find_element(By.CLASS_NAME,'gs_ai_aff').text\n",
    "                    \n",
    "                            co_authors_details.append({\n",
    "                                'name':name,\n",
    "                                'url': url,\n",
    "                                'aff':aff\n",
    "                            })\n",
    "\n",
    "                        close_button = driver.find_element(By.ID,'gsc_md_cod-x')\n",
    "                        close_button.click()\n",
    "                    else:\n",
    "                        co_authors_list = co_author_table.find_element(By.CLASS_NAME,'gsc_rsb_a').find_elements(By.TAG_NAME,'li')\n",
    "                        for co_author in co_authors_list:\n",
    "                            name = co_author.find_element(By.CLASS_NAME,'gsc_rsb_a_desc').find_element(By.TAG_NAME,'a').text\n",
    "                            url = co_author.find_element(By.CLASS_NAME,'gsc_rsb_a_desc').find_element(By.TAG_NAME,'a').get_attribute('href')\n",
    "                            aff = co_author.find_element(By.CLASS_NAME,'gsc_rsb_a_ext').text\n",
    "                                \n",
    "                            co_authors_details.append({\n",
    "                                'name':name,\n",
    "                                'url': url,\n",
    "                                'aff':aff\n",
    "                            })\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in Co-Authors Table for {author_full_name}\")\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "            prof_result['co_authors_url'] = co_authors_details\n",
    "            \n",
    "            prof_result['citation_table'] = {}\n",
    "            try:\n",
    "                # extracting citation table info\n",
    "                cols = []\n",
    "                ths = driver.find_element(By.ID, 'gsc_rsb_st').find_element(By.TAG_NAME,'thead').find_elements(By.CLASS_NAME,'gsc_rsb_sth')\n",
    "                for th in ths:\n",
    "                    if th.text!=\"\":\n",
    "                        cols.append(th.text)\n",
    "\n",
    "                prof_result['citation_table']['columns'] = cols\n",
    "                \n",
    "                trs = driver.find_element(By.ID, 'gsc_rsb_st').find_element(By.TAG_NAME, 'tbody').find_elements(By.TAG_NAME, 'tr')\n",
    "                for tr in trs:\n",
    "                    row_index = tr.find_element(By.CLASS_NAME,'gsc_rsb_sc1').text\n",
    "                    counts = [int(count.text) for count in tr.find_elements(By.CLASS_NAME,'gsc_rsb_std')]\n",
    "                    prof_result['citation_table'][row_index] = counts\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in Citation Table for {author_full_name}\") \n",
    "                print(e)\n",
    "\n",
    "            citation_graph = {}\n",
    "            try:\n",
    "                view_char_btn = driver.find_elements(By.ID, 'gsc_hist_opn')\n",
    "                if len(view_char_btn)>0:\n",
    "                    \n",
    "                    view_char_btn[0].click()\n",
    "                    time.sleep(3)\n",
    "\n",
    "                    graph = driver.find_element(By.ID,'gsc_md_hist_c').find_element(By.CLASS_NAME,'gsc_md_hist_b')\n",
    "                    years = graph.find_elements(By.CLASS_NAME,'gsc_g_t')\n",
    "                    citation_counts = graph.find_elements(By.CLASS_NAME,'gsc_g_a')\n",
    "\n",
    "                    for i in range(len(citation_counts)):\n",
    "                        style = citation_counts[i].get_attribute('style')\n",
    "                        year_index = int(style.split(':')[-1].strip(';'))\n",
    "                        citation_graph[int(years[-year_index].get_attribute('innerText'))] = int(citation_counts[i].get_attribute('textContent'))\n",
    "                    close_chart_btn = driver.find_element(By.ID,'gsc_md_hist-x')\n",
    "                    close_chart_btn.click()\n",
    "       \n",
    "            except Exception as e:\n",
    "                print(f\"Error in citation graph for {author_full_name}\")\n",
    "                print(e)\n",
    "\n",
    "            prof_result['citation_graph'] = citation_graph\n",
    "\n",
    "            articles = []\n",
    "            try:\n",
    "                # extracting articles info\n",
    "                btn = driver.find_element(By.ID,'gsc_bpf_more')\n",
    "                while btn.get_attribute('disabled') is None:\n",
    "                    btn.click()\n",
    "                    time.sleep(3)\n",
    "\n",
    "                article_url_list = []\n",
    "                trs = driver.find_element(By.ID, 'gsc_a_b').find_elements(By.CLASS_NAME, 'gsc_a_tr')\n",
    "                for tr in trs:\n",
    "                    article_url_list.append(tr.find_element(By.CLASS_NAME,'gsc_a_t').find_element(By.TAG_NAME,'a').get_attribute('href'))\n",
    "                    \n",
    "                driver.quit()\n",
    "\n",
    "                for article_url in article_url_list:\n",
    "                    driver = create_driver()\n",
    "                    driver.get(article_url)\n",
    "                    time.sleep(3)\n",
    "                    title = driver.find_element(By.ID, 'gsc_oci_title').find_element(By.TAG_NAME, 'a').text\n",
    "                    items = driver.find_element(By.ID, 'gsc_oci_table').find_elements(By.CLASS_NAME, 'gs_scl')\n",
    "\n",
    "                    article = {}\n",
    "                    article['title'] = title\n",
    "                    article['url'] = article_url\n",
    "                    for item in items:\n",
    "                        key = item.find_element(By.CLASS_NAME, 'gsc_oci_field')\n",
    "                        value = item.find_element(By.CLASS_NAME, 'gsc_oci_value')\n",
    "                        key = key.text.strip().lower().replace(' ', '_')\n",
    "                        if key =='authors':\n",
    "                            article[key] = value.text.split(', ')\n",
    "                        if key=='publication_date':\n",
    "                            article[key] = value.text\n",
    "                        if key=='journal' or key=='book' or key=='conference':\n",
    "                            article[key] = value.text\n",
    "                        if key=='description':\n",
    "                            article[key]= value.text\n",
    "                        if key=='total_citations':\n",
    "                            # total citation count\n",
    "                            article[key] = int(value.find_element(By.TAG_NAME, 'a').text.split(' ')[-1])\n",
    "\n",
    "                            # citation count over the years\n",
    "                            years = value.find_elements(By.CLASS_NAME,'gsc_oci_g_t')\n",
    "                            citations = value.find_elements(By.CLASS_NAME,'gsc_oci_g_a')\n",
    "                            value_2 = {int(year.get_attribute('innerText')):0 for year in years}\n",
    "                            for citation in citations:\n",
    "                                year = int(citation.get_attribute('href')[-4:])\n",
    "                                value_2[year] = int(citation.get_attribute('textContent'))\n",
    "                            article['citation_graph'] = value_2\n",
    "                    articles.append(article)\n",
    "                    driver.quit()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in Articles for {author_full_name}\")\n",
    "                print(e)\n",
    "            prof_result['articles'] = articles\n",
    "            \n",
    "        # No need to search through all name_permutations as best candidate has been found\n",
    "        if max_index != None:\n",
    "            break\n",
    "    filename = \"goog_sch_\"+author_full_name.lower().replace(' ','_')+'.json'\n",
    "    save_prof_details(details=prof_result,filename=filename)\n",
    "                \n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv('Kee_Kai_Teng.csv')\n",
    "result_df = result_df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in Articles for Anupam Chattopadhyay\n",
      "Message: no such element: Unable to locate element: {\"method\":\"tag name\",\"selector\":\"a\"}\n",
      "  (Session info: headless chrome=118.0.5993.117); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000105a3be08 chromedriver + 5025288\n",
      "1   chromedriver                        0x0000000105a32c23 chromedriver + 4987939\n",
      "2   chromedriver                        0x00000001055d4e67 chromedriver + 409191\n",
      "3   chromedriver                        0x00000001056241b9 chromedriver + 733625\n",
      "4   chromedriver                        0x0000000105624371 chromedriver + 734065\n",
      "5   chromedriver                        0x0000000105617b66 chromedriver + 682854\n",
      "6   chromedriver                        0x000000010564b50d chromedriver + 894221\n",
      "7   chromedriver                        0x0000000105617a28 chromedriver + 682536\n",
      "8   chromedriver                        0x000000010564b69e chromedriver + 894622\n",
      "9   chromedriver                        0x0000000105667571 chromedriver + 1009009\n",
      "10  chromedriver                        0x000000010564b2b3 chromedriver + 893619\n",
      "11  chromedriver                        0x0000000105615eb9 chromedriver + 675513\n",
      "12  chromedriver                        0x00000001056170ee chromedriver + 680174\n",
      "13  chromedriver                        0x00000001059fd819 chromedriver + 4769817\n",
      "14  chromedriver                        0x0000000105a02893 chromedriver + 4790419\n",
      "15  chromedriver                        0x0000000105a0966e chromedriver + 4818542\n",
      "16  chromedriver                        0x0000000105a035bd chromedriver + 4793789\n",
      "17  chromedriver                        0x00000001059d598c chromedriver + 4606348\n",
      "18  chromedriver                        0x0000000105a21b78 chromedriver + 4918136\n",
      "19  chromedriver                        0x0000000105a21d30 chromedriver + 4918576\n",
      "20  chromedriver                        0x0000000105a3285e chromedriver + 4986974\n",
      "21  libsystem_pthread.dylib             0x00007ff8086f4202 _pthread_start + 99\n",
      "22  libsystem_pthread.dylib             0x00007ff8086efbab thread_start + 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.iloc[2:]['Name'].apply(scrape_goog_sch_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_name_list = ['Anupam Chattopadhyay','Anwitaman Datta','Kwoh Chee Keong','Chng Eng Siong','Seah Hock Soon','Jagath Chandana Rajapakse','Zheng Jianmin','Chia Liang Tien','A S Madhukumar','Lam Siew Kei','Sourav Saha Bhowmick','Wentong Cai',\"Sun Aixin\",\"Erik Cambria\",'Chen Change Loy',\"Guan Cuntai\",\"Dusit Niyato\",\"Cong Gao\",\"Lin Guosheng\",\"Yu Han\",\"Zhang Hanwang\",\"Luo Jun\",\"Liu Weichen\",'Luke Ong （翁之昊）',\"Qian Kemao\",'Mohamed M. Sabry',\"Owen Noel Newton Fernando\",\"Joty Shafiq Rayhan\",\"Tan Rui\",'Pan Xingang',\"Liu Yang\",'Wen Yonggang',\"Li Yi\",\"Zhang Jie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CZ4125",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
