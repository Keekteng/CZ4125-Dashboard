{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = './prof_raw_data/'\n",
    "gpt_dir = './gpt_data/'\n",
    "processed_dir = './processed_data/'\n",
    "goog_prefix = 'goog_sch_'\n",
    "dr_ntu_prefix = 'dr_ntu_'\n",
    "education_prefix = 'education_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scse_profile = pd.read_csv('./prof_raw_data/scse_profiles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publications per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pubs(articles):\n",
    "    cur_year = datetime.date.today().year\n",
    "    min_year  = np.inf\n",
    "    pub_yearly = {}\n",
    "    for article in articles:\n",
    "        if 'publication_date' in article:\n",
    "            pub_year = int(article['publication_date'].split('/')[0])\n",
    "            min_year = min(min_year,pub_year)\n",
    "            # unknown publish date\n",
    "            if pub_year>cur_year:\n",
    "                continue \n",
    "            else:               \n",
    "                pub_yearly[pub_year] = pub_yearly.get(pub_year,0) + 1\n",
    "    \n",
    "    # Filling in 0 for years without papers\n",
    "    for year in range(min_year,cur_year+1):\n",
    "        if year not in pub_yearly:\n",
    "            pub_yearly[year] = 0\n",
    "\n",
    "    return pub_yearly,min_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations Per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_citation(articles):\n",
    "    cur_year = datetime.date.today().year\n",
    "    min_year  = np.inf\n",
    "    citations_yearly = {}\n",
    "    for article in articles:\n",
    "        if 'citation_graph' in article and 'publication_date' in article:\n",
    "            pub_year = int(article['publication_date'].split('/')[0])\n",
    "            min_year = min(min_year,pub_year)\n",
    "\n",
    "            for year,citation_count in article['citation_graph'].items():\n",
    "                year = int(year)\n",
    "                if year<=cur_year:\n",
    "                    citations_yearly[year] = citations_yearly.get(year,0)+citation_count\n",
    "    \n",
    "\n",
    "    # Filling in 0 for years without citations\n",
    "    for year in range(min_year,cur_year+1):\n",
    "        if year not in citations_yearly:\n",
    "            citations_yearly[year] = 0\n",
    "    final_citations_yearly = {}\n",
    "    # Remove year < earliest publication_date, not possible to have citation before earliest publication date\n",
    "    for year,citation_count in citations_yearly.items():\n",
    "        if int(year)>=min_year:\n",
    "            final_citations_yearly[year] = citations_yearly[year]\n",
    "        \n",
    "\n",
    "    return final_citations_yearly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Citations per Paper per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_citation(pubs_yearly,citation_yearly,pub_min_year):\n",
    "    avg_citation = {}\n",
    "    cur_year = datetime.date.today().year\n",
    "    citation_min_year = min(citation_yearly.keys())\n",
    "    if citation_min_year==pub_min_year:        \n",
    "        for year in range(pub_min_year,cur_year+1):\n",
    "            pub_count_to_date = 0\n",
    "            cite_count_to_date = 0\n",
    "            for temp_year in range(pub_min_year,year+1):\n",
    "                pub_count_to_date += pubs_yearly[temp_year]\n",
    "                cite_count_to_date += citation_yearly[temp_year]\n",
    "            avg_citation[year] = cite_count_to_date/pub_count_to_date\n",
    "    else:\n",
    "        for year in range(pub_min_year,citation_min_year):\n",
    "            avg_citation[year] = 0\n",
    "        for year in range(citation_min_year,cur_year):\n",
    "            pub_count_to_date = 0\n",
    "            cite_count_to_date = 0\n",
    "            for temp_year in  range(citation_min_year,year+1):\n",
    "                pub_count_to_date+= pubs_yearly[temp_year]\n",
    "                cite_count_to_date+=citation_yearly[temp_year]\n",
    "            avg_citation[year] = cite_count_to_date/pub_count_to_date\n",
    "\n",
    "    return avg_citation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h-Index\n",
    "\n",
    "- Calculate All-Time h-Index over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_h_index(articles):\n",
    "    h_index_yearly = {}\n",
    "\n",
    "    #current year\n",
    "    cur_year = datetime.date.today().year\n",
    "    # finding earliest publication date\n",
    "    min_year = np.inf\n",
    "    for article in articles:\n",
    "        if 'citation_graph' in article and 'publication_date' in article:\n",
    "            pub_year = int(article['publication_date'].split('/')[0])\n",
    "            min_year = min(min_year,pub_year)\n",
    "            if pub_year > cur_year:\n",
    "                continue\n",
    "            citation_count = 0\n",
    "            for year in range(pub_year,cur_year+1):\n",
    "                citation_count += article['citation_graph'].get(str(year),0)\n",
    "                h_index_yearly[year] = h_index_yearly.get(year,[]) + [citation_count]\n",
    "    for year in h_index_yearly:\n",
    "        h_index_value = sum(citation_counts>=idx+1 for idx, citation_counts in enumerate(sorted(h_index_yearly[year],reverse=True)))\n",
    "        h_index_yearly[year] = h_index_value\n",
    "\n",
    "    return h_index_yearly    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboration Network\n",
    "\n",
    "- Process co authors in a way suitable for creating network graph on dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_co_authors(co_authors_url):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging all Data Sources\n",
    "\n",
    "- gpt_data, prof_raw_data and collaboration_network data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in scse_profile['name']:\n",
    "    filename = name.lower().replace(' ','_')\n",
    "    # read from raw data source and gpt data source\n",
    "    with open(f\"{raw_dir}{goog_prefix}{filename}.json\",'r') as f:\n",
    "        goog_sch_profile = json.load(f)\n",
    "\n",
    "    with open(f\"{raw_dir}{dr_ntu_prefix}{filename}.json\",'r')as f:\n",
    "        dr_ntu_profile = json.load(f)\n",
    "\n",
    "    with open(f\"{gpt_dir}{education_prefix}{filename}.json\") as f:\n",
    "        education_info = json.load(f)\n",
    "\n",
    "    # keys to add directly to merged profile\n",
    "    goog_sch_keys = ['goog_sch_url','interests','citation_table','citation_graph']\n",
    "    dr_ntu_keys = ['full_name','email','name_card','designations','urls','biography','grants','keywords']\n",
    "    \n",
    "    merged_profile = {}\n",
    "\n",
    "    for key in dr_ntu_keys:\n",
    "        merged_profile[key] = dr_ntu_profile[key]\n",
    "    \n",
    "    # Skip empty goog scholar profiles\n",
    "    if goog_sch_profile:\n",
    "        for key in goog_sch_keys:\n",
    "            merged_profile[key] = goog_sch_profile[key]               \n",
    "    \n",
    "    # add education background information generated from chatgpt\n",
    "    merged_profile['education'] = education_info\n",
    "\n",
    "    pub_yearly = {}\n",
    "    citation_yearly = {}\n",
    "    h_index_yearly = {}\n",
    "    avg_citation_yearly = {}\n",
    "    if 'articles' in goog_sch_profile:\n",
    "        # adding pre-processed information\n",
    "        pub_yearly,min_year = calc_pubs(goog_sch_profile['articles'])\n",
    "        citation_yearly = calc_citation(goog_sch_profile['articles'])\n",
    "        h_index_yearly = calc_h_index(goog_sch_profile['articles'])\n",
    "        avg_citation_yearly = calc_avg_citation(pub_yearly,citation_yearly,min_year)\n",
    "\n",
    "    merged_profile['pub_graph'] = pub_yearly\n",
    "    merged_profile['citation_graph'] = citation_yearly\n",
    "    merged_profile['h_index_graph'] = h_index_yearly\n",
    "    merged_profile['avg_citation_graph'] = avg_citation_yearly\n",
    "\n",
    "    with open(f\"{processed_dir}{filename}.json\",'w') as f:\n",
    "        json.dump(merged_profile,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CZ4125",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
